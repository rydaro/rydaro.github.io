<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>A Tutorial on Applying Propensity Score Methods Using a Large Medical Claims Database</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}

.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ryan Ross</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Propensity Tutorial</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">A Tutorial on Applying Propensity Score Methods Using a Large Medical Claims Database</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#background">Background</a><ul>
<li><a href="#variable-indentification-and-the-propensity-score">Variable Indentification and the Propensity Score</a></li>
<li><a href="#propensity-methods">Propensity Methods</a></li>
<li><a href="#balance-assessment">Balance Assessment</a></li>
<li><a href="#treatment-effect-estimation-and-sensitivity-analysis">Treatment Effect Estimation and Sensitivity Analysis</a></li>
</ul></li>
<li><a href="#examplecomparing-oral-hormone-therapy-vs.immunotherapy-for-advanced-prostate-cancer">Example:Comparing Oral Hormone Therapy vs. Immunotherapy for Advanced Prostate Cancer</a><ul>
<li><a href="#covariates">Covariates</a></li>
<li><a href="#outcomes">Outcomes</a></li>
<li><a href="#propensity-analysis">Propensity Analysis</a><ul>
<li><a href="#propensity-score-estimation">Propensity Score Estimation</a></li>
<li><a href="#propensity-score-matching">Propensity Score Matching</a></li>
<li><a href="#inverse-probability-treatment-weighting">Inverse Probability Treatment Weighting</a></li>
<li><a href="#assessment-of-covariate-balance">Assessment of Covariate Balance</a></li>
</ul></li>
<li><a href="#treatment-effect-estimation">Treatment Effect Estimation</a><ul>
<li><a href="#binary-outcome-visit-to-the-emergency-room-er-in-60-days">Binary Outcome: Visit to the Emergency Room (ER) in 60 days</a></li>
<li><a href="#count-outcome-number-of-emergency-room-er-visits-in-180-days">Count Outcome: Number of Emergency Room (ER) visits in 180 days</a></li>
<li><a href="#length-of-stay-outcomes-time-on-treatment-and-time-enrolled">Length of Stay Outcomes: Time on Treatment and Time Enrolled</a></li>
<li><a href="#time-varying-outcome-opioid-usage-post-treatment">Time Varying Outcome: Opioid Usage Post Treatment</a></li>
</ul></li>
<li><a href="#discussion">Discussion</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul>
</div>

<div id="abstract" class="section level2">
<h2>Abstract</h2>
<p>Medical insurance claims are becoming increasingly common data sources to answer a variety of questions in biomedical research. Although comprehensive in terms of longitudinal characterization of disease development and progression for a potentially large number of patients, population-based studies using these datasets require thoughtful modification to sample selection and analytic strategies, relative to other types of studies. Along with complex selection bias and missing data issues, claims-based studies are purely observational, which limits effective understanding and characterization of the treatment differences between groups being compared. Several methods have been developed to better estimate causal treatment effects from observational studies, often using the propensity score in various ways. This paper offers some practical guidance to researchers in using propensity-based methods for estimating causal treatment effects on several types of outcomes common to medical studies, such as binary, count, time to event and longitudinally varying repeated measures outcomes. We provide an online version of the paper with readily implementable code to serve as a guided tutorial for practitioners. The methods are illustrated using a sub-cohort of patients with prostate cancer from the large Clinformatics TM Data Mart Database (OptumInsight, Eden Prairie, Minnesota), consisting of 73 million distinct insurees from 2001-2016. We demonstrate estimation for each type of outcome with examples from the data, such as emergency room (ER) visits and opioid prescription fills.</p>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Health service billing data can be used to answer clinical and epidemiological questions using a large number of patients and has the potential to capture patterns in health care practice that take place in the real world. Such large datasets allow investigators to conduct scientific queries which may be difficult, if not practically impossible, to answer via a randomized clinical trial. For example, comparing multiple treatments that are produced by different drug companies and with varying guidelines for their use for a disease may only be feasible in a real healthcare database. Although these large data sources offer a wealth of information, there are many challenges and drawbacks, such as confounding, selection bias, heterogeneity, missing values and misclassification of disease and exposures. For example, ICD codes are entered by the care provider, and thus certain diagnoses may be missed or may not be accurate or may differ across providers.<span class="math inline">\(^{[1]}\)</span> Motheral et al<span class="math inline">\(^{[2]}\)</span> address many of the common issues and provide guidelines for researchers when using these data sources. Regulatory agencies and pharmaceutical companies are increasingly considering real world evidence present in such databases in concert with randomized clinical trials.<span class="math inline">\(^{[3]}\)</span></p>
<p>Often, researchers wish to characterize the effect that an exposure, intervention, or treatment has on a given outcome with this readily available type of data. When characterizing a treatment effect on an outcome, randomized control trials are the gold standard. Randomization aims to ensure that the treatment and control groups are similar and considered “exchangeable.” However, randomized clinical trials are often only able to reflect a narrow clinical application due to restrictive inclusion/exclusion criteria. Claims data have the benefit of reflecting how medications are actually being prescribed, and thus may provide a more accurate depiction of treatment benefit in practice or real life evidence. With claims data, the assignment of treatment is not random, and thus susceptible to confounding and selection bias. In practice, the clinician and patient decide among treatment options based on the patient’s circumstances and overall health. Further, these same factors may also be associated with the health outcome of interest. If not properly incorporated, these factors will misrepresent and bias the true treatment effect comparison. Many have proposed general guidelines for analysis using claims data for comparative effectiveness research to address such issues.<span class="math inline">\(^{[3,4,5,6]}\)</span> While there are several approaches to handling confounding and selection bias available, propensity score-based methods are versatile in that they can be used for a variety of research questions and can be used for many different kinds of study designs and databases. Thus, these methods have gained increasing popularity, especially for questions of comparative effectiveness in pharmacoepidemiologic and pharmacoeconomic research.</p>
<p>A downside to this rise in popularity is that the assumptions and critical steps for the methods are often ignored or unreported. Ali et al<span class="math inline">\(^{[7]}\)</span> found 296 published medical papers in a 6-month period that reported use of a propensity score method. However, in their systematic review, they found that 194 (65.5%) did not report how variables were selected for the propensity model, and that only 177 (59.8%) reported test for balance of confounders between the two groups of comparison. Others have also noted common misuse of propensity methods.<span class="math inline">\(^{[8,9,10,11]}\)</span> Yao et al<span class="math inline">\(^{[12]}\)</span> concluded in a recent systematic review of cancer studies that there is considerable room for improvement in reporting propensity analysis and offered guidelines for such reporting. Yet, some researchers are still not clear with their use of propensity methods and its presentation in a scientific paper. For example, when comparing the effectiveness of allopurinol or febuxostat on reducing the risk of atrial fibrillation, Singh et al<span class="math inline">\(^{[13]}\)</span> matched subjects based on the propensity score. While they did report which variables were used for propensity construction and balance diagnostics after matching, many important details were not reported. Analysis questions arise, such as how the propensity score was calculated (logistic regression or otherwise), what distance measure was used to match subjects, and if subjects were matched with or without replacement. These details are essential for researchers wishing to replicate the results reported. The lack of detailed reporting and frequent misuse of propensity methodology propels the need for more effective practical guidance.</p>
<p>Austin<span class="math inline">\(^{[14]}\)</span> provides a conceptual overview of propensity score methods from a foundational and introductory standpoint. Stuart et al<span class="math inline">\(^{[15]}\)</span> provide a general framework for using propensity methods with observational health care data, providing an example of effect estimation of drug monitoring programs for individuals with serious mental illness. Additionally, Brookhart et al<span class="math inline">\(^{[16]}\)</span> provide practical example when comparing the risk of angioedema between two treatments for hypertension. While these papers offer an elegant and lucid exposition of the underlying principles, and are extremely important contribution to the literature, these overviews do not offer the reader complete practical guidance, as there remains a gap from methodological understanding to actual implementation. Further, these tutorials do not directly address the use of propensity methods for a range of outcomes common to medical research, such as non-continuous or correlated outcomes. For example, a researcher may be interested in if a rare adverse event occurs or not (categorical) or monitoring a patient’s disease progression over the course of several visits (correlated repeated measures).There are unique assumption and considerations when using propensity methods for these different types of outcomes beyond those use for a simple scalar outcome, Therefore, there is need for a usable, simple and comprehensive tutorial for characterizing a binary treatment effect on various outcome types and accompanying software codes. This paper outlines the use of two primary propensity score-based methods: Propensity Matching (PM) and Inverse Probability of Treatment Weighting (IPTW). The paper also details how to use each method to estimate average treatment effect for four common outcome types: 1) Binary, 2) Count, 3) Time to event, and 4) Longitudinally varying repeated measures.</p>
<p>To illustrate these different propensity score methods using an insurance claims dataset, we chose to study treatment patterns and treatment outcomes among patients with advanced prostate cancer from the Clinformatics TM Data Mart Database (OptumInsight, Eden Prairie, Minnesota). This database has a wealth of de-identified medical claims, pharmacy claims, inpatient confinement information, provider information, and socio-demographic information. Each outcome type is defined from emergency room visits, time on treatment and enrolled, and prescription fills for opioids.</p>
</div>
<div id="background" class="section level2">
<h2>Background</h2>
<p>Causal inference relies on the potential-outcomes framework, where each individual has a potential outcome under each possible treatment not assigned to him/her.<span class="math inline">\(^{[17]}\)</span> Typically, this framework applies to two possible available treatments, such as treatment of interest compared to another treatment for the same disease, or more simply an active treatment to no treatment. As described by Rubin,<span class="math inline">\(^{[17,18]}\)</span> many causal inference problems involve comparison of potential outcomes on the same (say <span class="math inline">\(i^{th}\)</span>) individual. Define <span class="math inline">\(Y_{i}(0)\)</span> as the observed outcome under the control treatment, and <span class="math inline">\(Y_{i}(1)\)</span> as the potential outcome under the active treatment of interest. We wish to know the treatment effect for each individual defined as <span class="math inline">\(Y_{i}(1) - Y_{i}(0)\)</span>, which cannot be estimated directly from the observed data because for each individual we observe either <span class="math inline">\(Y_{i}(0)\)</span> or <span class="math inline">\(Y_{i}(1)\)</span>, but never both. If subject <span class="math inline">\(i\)</span> actually received the active treatment, denoted by <span class="math inline">\(T_i=1\)</span> then <span class="math inline">\(Y_{i}(1)\)</span> is observed and <span class="math inline">\(Y_i =Y_{i}(1)\)</span>; otherwise, <span class="math inline">\(T_i=0\)</span>, and we observe <span class="math inline">\(Y_i=Y_{i}(0)\)</span>, under the stable unit treatment value assumption. Often, researchers are interested in how patients receiving a specific treatment compares to a comparison group within a larger population. We can define the average treatment effect (ATE) as <span class="math inline">\(E[Y_{i}(1) - Y_{i}(0)]\)</span>,which is the average treatment effect across the entire population.19 In a randomized trial, we can estimate ATE as <span class="math inline">\(E[Y_{i}(1) - Y_{i}(0)] = E[Y_i|T_i=1] - E[Y_i|T_i=0]\)</span> as randomization ensures that the treatment groups are balanced and hence <span class="math inline">\(E[Y_i(a)] = E[Y_i(a)|T_i=a] = E[Y_i|T_i=a]\)</span> for all <span class="math inline">\(a = 0,1\)</span> 14,20 We can also define the average treatment effect on the treated (ATT) as <span class="math inline">\(E[Y_i(1)− Y_i(0)|T = 1]\)</span> and the average treatment effect on the control (ATC) as <span class="math inline">\(E[Y_i(1)− Y_i(0)|T = 0]\)</span> when a particular sub-population is of interest.</p>
<p>A simple approach to look at a difference in an outcome is a general linear model with the treatment variable as the sole predictor is</p>
<p><span class="math display">\[
g(\mu_{i}) = \beta_{0} +\beta_{1}T_{i}
\]</span> where <span class="math inline">\(\mu_{i} = E[Y_{i}|T_i]\)</span> and <span class="math inline">\(\beta_1\)</span> is the parameter of interest for treatment comparison. In the simple linear regression case where <span class="math inline">\(g()\)</span> is the identity function, <span class="math inline">\(\beta_1 = E[Y_i|T_i=1] - E[Y_i|T_i=0]\)</span>. This is the standard method for data from a randomized trial. With observational studies, however, the mechanism behind treatment assignment is not random, and thus the treatment populations may differ greatly. Therefore <span class="math inline">\(E[Y(1)|T = 1] \neq E [Y(1)]\)</span> and <span class="math inline">\(E[Y(0)|T = 0] \neq E [Y(0)]\)</span> in general.14 As a result, the estimate for ATE will be biased due to confounding. Traditionally, confounders were adjusted for directly in the outcome model to obtain an estimate of ATE. However useful, estimates from this approach may be unreliable where there are many covariates with potential non-linearity and interactions, the groups of comparison are greatly imbalanced on one or several confounders, or the confounders are highly correlated. With the large number of variables seen in health care databases, this approach is often not feasible due to the large dimension of the adjusted model and the possibility of model misspecification. The notion of the propensity score, a unidimensional construct, offers alternative analytical approaches that are more suitable for this type of data. Using the propensity score in analysis involves several steps that have to be exercised with caution, as outlined in Figure 1. Below, we outline each step and demonstrate the process.</p>
<center>
<div class="figure">
<img src="PS_Diagram.png" alt="Figure 1: Flow diagram of stages of propensity score analysis. Gold pathway indicates steps done in iteration until acceptable balance is achieved." />
<p class="caption">Figure 1: Flow diagram of stages of propensity score analysis. Gold pathway indicates steps done in iteration until acceptable balance is achieved.</p>
</div>
</center>
<div id="variable-indentification-and-the-propensity-score" class="section level3">
<h3>Variable Indentification and the Propensity Score</h3>
<p>Proposed by Rosenbaum and Rubin,<span class="math inline">\(^{[21]}\)</span> the propensity score is <span class="math inline">\(e_{i}= Pr(T_{i} = 1| X_{i} =x)\)</span> . The score can be interpreted as the probability a subject receives treatment conditional on the covariates <span class="math inline">\(X_{i}\)</span>. Rosenbaum and Rubin<span class="math inline">\(^{[21]}\)</span> showed that conditional on the propensity score, an unbiased estimate of ATE can be obtained if the treatment is strongly ignorable. A treatment is strongly ignorable if two conditions are met: 1) <span class="math inline">\(0 &lt;P(T_{i}=1|X_{i})&lt;1\)</span> and <span class="math inline">\((Y_i(0),Y_i(1)) \perp \perp T_i|X_i\)</span> <span class="math inline">\(^{[21]}\)</span></p>
<p>The second of these assumptions is the “no unmeasured confounders” assumption. Thus, a critical assumption for use of the propensity score is that all variables that affect the outcome and treatment assignment are measured. If all confounding variables are identified and included, and the model is correctly specified, this score achieves covariate balance between treatment and control groups. With the treatment groups more comparable, we can better characterize the treatment’s effect on the outcome of interest. We can estimate this probability using logistic regression, predicting treatment received from our observed covariates, expressed as <span class="math display">\[log\frac{e_{i}}{(1-e_{i})} = X_{i}^T\gamma\]</span> and thus <span class="math display">\[e_{i} = \dfrac{1}{1+exp(-X_{i}^T\gamma)}\]</span></p>
<p>While logistic regression is commonly used to estimate this propensity score, researchers have expanded their attention beyond parametric models. Many have used machine learning methods such as boosted logistic regression, random forests, and neural networks.<span class="math inline">\(^{[22,23,24]}\)</span> Imai and Ratkovic<span class="math inline">\(^{[25]}\)</span> propose the Covariate Balancing Propensity Score (CBPS) as a generalized method of moments estimate that operationalizes on the propensity score’s two characteristics as a covariate balancing score and the conditional probability of treatment assignment, shown to perform well in certain applications.<span class="math inline">\(^{[26]}\)</span> We do note that the ultimate goal of the propensity model is not to predict treatment assignment, but to reduce bias by balancing covariates.<span class="math inline">\(^{[27]}\)</span></p>
<p>Still, the treatment effect estimation methods are sensitive to misspecification of the propensity score model, and thus the variables and their functional forms used in this model can affect the estimation of average treatment effect. Many suggest including all variables at all associated with the outcome, while excluding those only associated with the treatment of interest, based on subject-matter knowledge<span class="math inline">\(^{[16,28,29,30]}\)</span> Vanderweele<span class="math inline">\(^{[31]}\)</span> provides a general guide to confounder selection in observational studies. Such variables may be difficult to identify in large databases, and thus several authors have proposed automated data-adaptive variable selection tools for high-dimensional propensity score models.<span class="math inline">\(^{[32,33]}\)</span> This paper focuses on estimation of the propensity score through logistic regression and CBPS with a modest number of covariates</p>
</div>
<div id="propensity-methods" class="section level3">
<h3>Propensity Methods</h3>
<p>Once the propensity score is constructed, there are four basic ways to use the score in treatment effect estimation: 1) Stratification based on the propensity score, 2) Direct covariate adjustment using propensity score as a covariate in the outcome model, 3) Matching treatments and controls based on the propensity score (PM), and 4) Inverse probability treatment weighting on the propensity score (IPTW). Stratification ranks subjects by the estimated propensity score and splits them into mutually exclusive stratum. The treatment effect in each stratum can then be estimated and pooled to obtain an overall treatment effect.34 Direct covariate adjustment uses the propensity score in the outcome model as a covariate, often a non-parametric smoothing term using a spline function with the propensity score as an argument is used. We will not discuss the first two methods at length, as they are used less commonly, and research suggests they may be biased for non-continuous outcomes.35,36 The rest of this paper will focus on the more common methods, PM and IPTW.</p>
<div id="propensity-matching" class="section level4">
<h4>Propensity Matching</h4>
<p>The first method discussed is matching observations based on the propensity score to estimate ATT. Often, exactly identical scores do not exist across individuals, and thus matching requires a clear definition of “closeness” of propensity based on a measure of distance.<span class="math inline">\(^{[37,38]}\)</span> Stuart<span class="math inline">\(^{[38]}\)</span> provides a comprehensive overview of the various matching methods available. In practice, it is common to do <span class="math inline">\(1:1\)</span> matching, where each individual in the treatment group is matched to a single individual in the comparison group, based on the predefined measure of closeness. This matching ratio can result in major loss of data, especially if the treatment groups are of very different sizes. An alternative is using <span class="math inline">\(1:k\)</span> matching, where <span class="math inline">\(k\)</span> is a max number of controls. With a defined distance, called a caliper, all potential matches within the distance up to <span class="math inline">\(k\)</span> will be matched. This allows for maximal efficiency of data while still reducing bias since all close matches are kept. There is little guidance on what caliper a researcher should specify; however, Austin<span class="math inline">\(^{[39]}\)</span> suggests a caliper of <span class="math inline">\(0.2\)</span> standard deviations of the logit of the propensity score as a default choice that works well across scenarios.</p>
</div>
<div id="inverse-probability-of-treatment-weighting-iptw" class="section level4">
<h4>Inverse Probability of Treatment Weighting (IPTW)</h4>
<p>The next method we consider is the inverse probability of treatment (IPTW) proposed by Rosenbaum.40 We can calculate the IPTW <span class="math inline">\(v_i\)</span> as <span class="math display">\[
v_{i} = \dfrac{T_{i}}{\hat{e}_{i}} + \dfrac{(1-T_{i})}{(1-\hat{e}_{i})}
\]</span> where <span class="math inline">\(\hat{e_i}\)</span> is the estimated propensity score. The outcome model can be fit directly using these weights, similar to survey sample weighting.<span class="math inline">\(^{[41,42]}\)</span> These weights can be very unstable for extreme values of <span class="math inline">\(\hat{e_i}\)</span>, so trimming these values away from the extreme is often practiced.<span class="math inline">\(^{[43,44]}\)</span> The construction of weights used here estimates ATE, and different constructions can be used for ATT and other effect estimates of interest.<span class="math inline">\(^{[45]}\)</span></p>
</div>
</div>
<div id="balance-assessment" class="section level3">
<h3>Balance Assessment</h3>
<p>Before analyzing the outcome, it is good practice to check to see if the chosen propensity method achieved its goal of balancing the covariates. While there are several balance diagnostics a common balance diagnostic originally proposed by Rosenbaum and Rubin<span class="math inline">\(^{[47]}\)</span> is the standardized difference (or standardized bias) for <span class="math inline">\(1:1\)</span> matching, defined as <span class="math display">\[
  \frac{\bar{x}_{t} - \bar{x}_{c}}{s_{p}}
\]</span> This is the difference in mean value of the covariate in the treatment group vs. the control group, adjusting for variability, where <span class="math inline">\(s_{p}\)</span> is the pooled standard deviation defined as <span class="math inline">\(s_{p}=\sqrt{\frac{s_{t}^2 +s_{c}^2}{2}}\)</span>.<span class="math inline">\(^{[47,48]}\)</span> This value is calculated for each covariate, with values closer to zero indicating less bias. The measure can be calculated for both continuous and categorical indicator variables.<span class="math inline">\(^{[4,48]}\)</span> A lack of balance indicates that the propensity model may be incorrect, or that a different method should be used. There is no generally accepted threshold, although some suggest that the standardized difference should not be greater than <span class="math inline">\(|0.1|\)</span> <span class="math inline">\(^{[47,48]}\)</span> We can generalize this difference for <span class="math inline">\(1:k\)</span> matching and assessing balance when using IPTW by using weights when calculating the means and standard deviations.<span class="math inline">\(^{[49]}\)</span> The weighted mean is defined as <span class="math inline">\(\bar{x}_{w} = \frac{\sum w_{i}x_{i}}{\sum w_i}\)</span> and the weighted standard deviaion is <span class="math display">\[
s_{w} = \sqrt{\dfrac{\sum w_{i}(x_i - \bar{x}_{w})^2}{\frac{\sum w_{i}}{(\sum w_i)^2 - \sum {w_i}^2}}}
\]</span> where <span class="math inline">\(w_i\)</span> is the weight for subject <span class="math inline">\(i\)</span>. For <span class="math inline">\(1:1\)</span> matching, all observations have equal weight. If 1:k matching is used, observations in the control treatment group have <span class="math inline">\(1/k\)</span> weights and treated observations have weights <span class="math inline">\(1\)</span>. For IPTW, the calculated weights can be used, so <span class="math inline">\(v_i = w_i\)</span> for each observation. If sufficient balance is not met, the process of propensity score construction and balance assessment is repeated, changing to the propensity model or matching methods used.</p>
</div>
<div id="treatment-effect-estimation-and-sensitivity-analysis" class="section level3">
<h3>Treatment Effect Estimation and Sensitivity Analysis</h3>
<p>Once sufficient balance has been achieved, one can estimate the average treatment effect using a general outcome model <span class="math display">\[
g(\mu_{i}) = \beta_{0} +\beta_{1}T_{i}
\]</span></p>
<p>This model can be used directly on the matched dataset if <span class="math inline">\(1:1\)</span> matching is used. If <span class="math inline">\(1:k\)</span> matching or IPTW is used, the constructing weights need to be used as well. Weights can be incorporated in the same fashion as weights from a survey design, using robust standard error estimation to account for error in weight estimation.<span class="math inline">\(^{[41,42]}\)</span> One can also test how sensitive the results are to unobserved confounders. We will not demonstrate such sensitivity analyses tools, however, Liu et al<span class="math inline">\(^{[50]}\)</span> provide an overview of these approaches.</p>
</div>
</div>
<div id="examplecomparing-oral-hormone-therapy-vs.immunotherapy-for-advanced-prostate-cancer" class="section level1">
<h1>Example:Comparing Oral Hormone Therapy vs. Immunotherapy for Advanced Prostate Cancer</h1>
<p>Many patients with advanced prostate cancer will receive a number of different therapies sequentially to try to control the disease and symptoms. Patients may have varying degrees of responsiveness and tolerance to different therapies during the period of treatment. For example, some patients who experience pain from their cancer will have pain relief after starting a treatment and thus require less opiates to manage their cancer. On the other hand, some patients will have poor tolerance of specific therapies and may experience exacerbation or development of comorbid conditions. It is also important to note that a treatment is typically only continued for as long as it is effectively controlling the disease or symptom. Thus, the longer a patient is on a treatment, presumably the longer the duration of effective disease control on that treatment.</p>
<p>We defined a cohort of men who received treatment for advanced prostate cancer, based on receiving one of six focus medications known to have a survival benefit in men with advanced prostate cancer (abiraterone, enzalutamide, sipuleucel-T, docetaxel, cabazitaxel, radium-223) from January 2010 through June 2016 from the Clinformatics TM Data Mart Insurance Claims Database. The initial cohort included any patient over the age of 18 with a diagnosis of malignant neoplasm of the prostate, coded as “185” in ICD-9 and “C61” in ICD-10. We restricted our final cohort to include patients that were continuously enrolled in the plan for the 180 days before the first medication claim. Finally, we wished to compare first-line therapies between patients where first-line treatment was defined as the first medication given of the six focus medications. We only kept only those whose first focus claim was abiraterone, enzalutamide, docetaxel, and sipuleucel-T, as the other two medications were rarely first-line and then categorized patients given abiraterone or enzalutamide as a common oral therapy group.</p>
<div id="covariates" class="section level3">
<h3>Covariates</h3>
<p>Age of the patient at the time of receipt of first-line treatment and patient sociodemographic variables were identified through enrollment records included in the OptumInsight database. A demographic-based analytical model is used by OptumInsight to derive many of the sociodemographic variables. The major data syndicator used is Knowledge-Based Marketing Solutions (KBM, Richardson, TX). Race was classified as white, black, Hispanic, or Asian. Geographic region of the patient was originally determined by their ZIP; however, this view of the data was encrypted so only a broader geographic region could be identified. Diabetes, hypertension, cardiac arrhythmias, congestive heart failure (CHF), and osteoporosis, were the pre-existing comorbid diseases we included in our analysis. To identify a pre-existing comorbid disease rather than a comorbid condition that may have resulted from treatment, the presence of a pre-existing comorbid disease was defined as at least two diagnosis codes within the two years before receipt of the first-line drug. The ICD-9 (2008-2012) and ICD-10 (2013-2016) codes are from Elixhauser Comorbidity Index and Clinical Classification Software.<span class="math inline">\(^{[51,52]}\)</span> Table 1 shows the descriptive characteristics of each of these variables across the three primary treatment groups.</p>
</div>
<div id="outcomes" class="section level3">
<h3>Outcomes</h3>
<p>We chose three different types of outcomes that are typically extracted from a claims database. We defined a binary outcome to be whether the patient had any emergency room (ER) visit within 60 days of the first pharmacy claim of the focus medications and used the number of ER visits each patient had within 180 days from the first pharmacy claim as a count outcome. ER visits were identified using Current Procedural Terminology (CPT) codes.</p>
<p>We were also interested in the overall survival of patients; however, exact death dates were unavailable with this version of the data. We thus considered two other time to event outcomes as possible surrogates: time on treatment and time enrolled. Time on treatment was defined as the time from start of first medication to the last claim of any of the six focus medications, thus the event is stopping all focus treatment permanently. Time enrolled was defined as the time from start of the first medication to the last claim for that subject within the Clinformatics TM Data Mart Database for any medical-related issue. This definition of time enrolled could be considered a censored surrogate for death because we expect most patients to have medical needs until shortly before death. These two endpoints differ in that some individuals may have stopped treatment from a focus medication, yet still used medical services and managed pain beyond ending treatment, while others may have been treated continuously until death. Patients would be expected to have less total time on treatment if they had a highly resistant cancer that would not respond to any treatments (and thus treatments would not be continued if they were ineffective), or if they had severe toxicities to treatment that did not allow for continuation. Also, these endpoints differed across treatment groups, with those on oral therapy continuing treatment near the end of enrollment, whereas chemotherapy patients may stop a year or more before ending enrollment.</p>
<p>For the final longitudinal varying repeated measures outcome, we used opioid usage over time, calculated using prescription drug pharmacy claims. Common opioid drug types were identified and were converted into morphine milligram equivalents (MME) according to the Center for Disease Control conversion factors.53 The total (MME) supply prescribed was calculated in 30-day periods, starting with the 30 days before the first-line of treatment, which was used as a baseline, and continuing at 30-day intervals for the duration of claims data available. Many patients with metastatic prostate cancer have pain from their disease that require opiates for pain control. Therefore, the level of MMEs may be a surrogate measure for disease burden, and disease response to treatment. Table 2 shows the descriptive summary of each of these outcome variables across the three primary treatment groups.</p>
</div>
<div id="propensity-analysis" class="section level2">
<h2>Propensity Analysis</h2>
<p>Empirically identifying the optimal sequence of therapies through disease course is a complex problem due to sparse sample size, once defining groups by specific orders of treatments and censoring. To determine which first-line treatment may lead to better outcomes regardless of which treatments a patient receives subsequently, we classified patients into one of the three categories of treatment that were prescribed first-line: oral therapy (abiraterone or enzalutamide), chemotherapy (docetaxel), or immunotherapy (sipuleucel-T). Since cabazitaxel and radium-223 were used infrequently as first-line treatments (n=110), we did not include patients who received cabazitaxel or radium-223 first-line in our analysis. We compared immunotherapy to oral therapy and compared immunotherapy to chemotherapy in two separate analyses. We chose immunotherapy as the reference group for both analyses, as it is the only treatment among the four included in the final analysis for which there is a clear treatment recommendation to be used in patients with minimally to asymptomatic metastatic castration-resistant prostate cancer. Our step-by-step example will primarily focus on the analysis process comparing immunotherapy to oral therapy. From Table 1, we can see that some covariates aren’t distributed the same across groups, such as income and provider specialty.</p>
<p>We can load all data into an active r session:</p>
<pre class="r"><code>#patient firsline information and demographic information
load(&#39;./firstline.Rdata&#39;)
#patient opioid filling information
load(&#39;./firstline_opioid.Rdata&#39;)
#change factor labels for better interpretability 
firstline_opioid$Treatment &lt;-factor(firstline_opioid$Brand,labels = c(&quot;Immunotherapy&quot;,&quot;Chemotherapy&quot;,&quot;Oral Therapy&quot;))

firstline_single$Treatment &lt;-factor(firstline_single$Brand,labels = c(&quot;Immunotherapy&quot;,&quot;Chemotherapy&quot;,&quot;Oral Therapy&quot;))
#alternative dataset for opioids, where 0&#39;s are filled in for all patient time points where no opioids were recorded
load(&quot;./firstline_zero.Rdata&quot;)

#we can explore and check the datasets
#check the size
dim(firstline_single)</code></pre>
<pre><code>## [1] 5463   23</code></pre>
<pre class="r"><code>#column names and the order
colnames(firstline_single)</code></pre>
<pre><code>##  [1] &quot;Patid&quot;        &quot;Brand&quot;        &quot;pae&quot;          &quot;pdoc&quot;        
##  [5] &quot;agecat&quot;       &quot;racecat&quot;      &quot;educat&quot;       &quot;housecat&quot;    
##  [9] &quot;Division&quot;     &quot;Product&quot;      &quot;met&quot;          &quot;Aso&quot;         
## [13] &quot;diabetes&quot;     &quot;hypertension&quot; &quot;CHF&quot;          &quot;osteoporosis&quot;
## [17] &quot;arrythmia&quot;    &quot;uro&quot;          &quot;enrolltime&quot;   &quot;er60&quot;        
## [21] &quot;ercount180&quot;   &quot;enroll_drug&quot;  &quot;Treatment&quot;</code></pre>
<pre class="r"><code>#load package that makes convenient discriptive summary
library(tableone)
#descriptive summaries 
print(CreateTableOne(vars=c(&quot;agecat&quot;),strata=c(&quot;Treatment&quot;),data=firstline_single,factorVars = c(&quot;agecat&quot;),test=FALSE))</code></pre>
<pre><code>##             Stratified by Treatment
##              Immunotherapy Chemotherapy Oral Therapy
##   n          504           2213         2746        
##   agecat (%)                                        
##      &lt;55      14 ( 2.8)      93 ( 4.2)    62 ( 2.3) 
##      55-64    87 (17.3)     329 (14.9)   341 (12.4) 
##      65-74   194 (38.5)     915 (41.3)   769 (28.0) 
##      &gt;75     209 (41.5)     876 (39.6)  1574 (57.3)</code></pre>
<div id="propensity-score-estimation" class="section level3">
<h3>Propensity Score Estimation</h3>
<p>We can construct a model for treatment assignment, <span class="math inline">\(T_{i}=0\)</span> if immunotherapy was given and <span class="math inline">\(T_{i}=1\)</span> if oral therapy was given using logistic regression, and the CBPS method. The logistic regression model included all variables shown in Table 1 as covariates and was constructed using the package <em>logistf</em><span class="math inline">\(^{[54]}\)</span> that uses Firth-corrected logistic regression to address any separation issues. From the regression results, we can calculate the estimated propensity score for each subject. It is often helpful to plot the distribution of propensity scores between the two groups of comparison, as shown in Figure 2, especially if matching subjects based on the propensity score. If there is little or no overlap in the distributions, many subjects will not be included in analysis as matches will not be found. The propensity score constructed from the CBPS approach was implemented through the R package <em>CBPS</em>.<span class="math inline">\(^{[25]}\)</span> The weights from this propensity score were used in the outcome models similar to the inverse probability weights.</p>
<pre class="r"><code>#create subsets for treating oral therapy and docetaxel separately
oral&lt;-firstline_single[firstline_single$pae&lt;99,]
oral$treatment&lt;-oral$pae

#restrict to subjects that were enrolled for at least 60 days for our 60 day outcome
oral60&lt;-oral %&gt;%
  filter(enrolltime &gt;=60)


#calculate propensity score using logistic regression model
prop_model &lt;-glm(treatment~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=oral60,family=binomial(link=&quot;logit&quot;))

#save predicted scores to dataset
oral60$pr_score &lt;-predict(prop_model,type=&quot;response&quot;)
#oral60$pr_score &lt;-prop_model$predict</code></pre>
<pre class="r"><code>g&lt;- ggplot(oral60,aes(x = pr_score, color=Treatment,fill=Treatment)) +
  geom_density(alpha=.47) + 
  xlab(&quot;Estimated Probability of Recieving Oral Therapy&quot;) +
  ylab (&quot;Density&quot;) +theme_minimal()+ theme(
                           axis.ticks.y=element_blank(),
                         panel.grid.minor=element_blank(),
                         legend.title=element_blank(),
                         text = element_text(size=16),
                         axis.title.x =element_text(hjust = 0.2,size=16))

ggpar(g,palette=&quot;nejm&quot;)</code></pre>
<p><img src="index_files/figure-html/ps%20plot-1.png" width="768" /></p>
<pre class="r"><code>library(CBPS)
#calculate weights using CBPS package and function
cbpsoral &lt;-CBPS(treatment~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=oral60,standardize=FALSE,method=&quot;exact&quot;,ATT=1)</code></pre>
<pre><code>## [1] &quot;Finding ATT with T=1 as the treatment.  Set ATT=2 to find ATT with T=0 as the treatment&quot;</code></pre>
<pre class="r"><code>oral60$cbps &lt;-cbpsoral$weights</code></pre>
</div>
<div id="propensity-score-matching" class="section level3">
<h3>Propensity Score Matching</h3>
<p>To create a matched dataset, we used the R package <em>Matchit</em>.<span class="math inline">\(^{[55]}\)</span> We defined our distance with logistic regression using the “nearest neighbor” method select matches within a defined caliper distance of <span class="math inline">\(0.2\)</span> standard deviations of the logit propensity score, with a variable matching ratio of $1:4 within the defined caliper. These matching specifications were chosen to ensure maximal efficiency of this data. If multiple close matches existed for a subject in the control group, those subjects were retained in the matched dataset. The caliper was decided using an iterative process, where several calipers were assessed and the one providing the highest quality matched sample was kept, based on the standardized differences across the covariates.</p>
<pre class="r"><code>#create matched dataset based on same propensity model
#here we switched the outcome, as matchit requires the larger group to be the reference if variable ratio is being used
#We are capturing up to 4 oral therapy matches for every sipuleucel-T subject
matched &lt;- matchit((1-treatment)~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data =oral60, method = &quot;nearest&quot;,caliper=.2,ratio=4)

#looked at characteristics of matched object
matched_sum&lt;-summary(matched)
matched_sum$nn</code></pre>
<pre><code>##           Control Treated
## All          2363     471
## Matched      1416     455
## Unmatched     947      16
## Discarded       0       0</code></pre>
<pre class="r"><code>#save matched dataset
matched_oral &lt;- match.data(matched)</code></pre>
</div>
<div id="inverse-probability-treatment-weighting" class="section level3">
<h3>Inverse Probability Treatment Weighting</h3>
<p>Weights were created from both the logistic regression and CBPS estimated propensity scores using the formula described above. Some weights were unstable, so propensity scores greater that <span class="math inline">\(0.99\)</span> were trimmed to <span class="math inline">\(0.99\)</span>, and scores below <span class="math inline">\(0.01\)</span> were trimmed to <span class="math inline">\(0.01\)</span>. Trimmed weights were used for analysis.</p>
<pre class="r"><code>#trim extreme values for stability
oral60$pr_score_trim &lt;-if_else(oral60$pr_score&lt;.01,.01,oral60$pr_score)
oral60$pr_score_trim &lt;-if_else(oral60$pr_score&gt;.99,.99,oral60$pr_score_trim)

#save the inverse weights from the propensity score
oral60$IPTW &lt;-oral60$treatment/oral60$pr_score_trim + (1-oral60$treatment)/(1-oral60$pr_score_trim)</code></pre>
</div>
<div id="assessment-of-covariate-balance" class="section level3">
<h3>Assessment of Covariate Balance</h3>
<p>Each method can be assessed for successful reduction in standardized difference for the analysis sample. Figure 3 shows a plot of the standardized difference of the covariates between the immunotherapy group, and oral therapy group for CBPS, IPTW and propensity matching methods. We can see that the inverse weighted data and the matched sample reduced the standardized difference for many covariates, even if perfect balance was not achieved. Unsurprisingly, the CBPS weights have very low/no bias, as the weights are constructed to achieve this goal of exact matching. With balance among the covariates achieved, we can now begin treatment effect estimation.</p>
<pre class="r"><code>###################figure
#for forest plot to check for bias
#create dummy variables for the many categorical variables
model_mat &lt;-model.matrix(~treatment +agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro -1,oral)

model_mat &lt;-data.frame(model_mat)
#model_mat$treatment &lt;-as.factor(model_mat$treatment)

#calculate means and standard deviations of each variable by group
fullsamp_means &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(mean))

fullsamp_var &lt;-model_mat %&gt;%
    group_by(treatment) %&gt;%
  summarise_all(funs(sd))

fullsamp_std &lt;-data.frame(t(fullsamp_var))
fullsamp_std$pooled &lt;- sqrt(((fullsamp_std[,1])^2 + (fullsamp_std[,2])^2)/2)

fullsamp&lt;-data.frame(t(fullsamp_means),fullsamp_std$pooled)

#calculate the standardized bias of the observed sample
colnames(fullsamp)&lt;-c(&quot;sip_mean&quot;,&quot;oral_mean&quot;,&quot;sd&quot;)
fullsamp$bias &lt;-(as.numeric(as.character(fullsamp$sip_mean))-as.numeric(as.character(fullsamp$oral_mean)))/as.numeric(as.character(fullsamp$sd))
fullsamp$group &lt;-rep(&quot;Observed&quot;,nrow(fullsamp))
fullsamp$label &lt;-rownames(fullsamp)


######matched group
#same calculations, now for the saved matched dataset
model_mat &lt;-model.matrix(~treatment +agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro+weights -1,matched_oral)

model_mat &lt;-data.frame(model_mat)
#model_mat$treatment &lt;-as.factor(model_mat$treatment)



matched_means &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(weighted.mean(., weights)))

matched_var &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(sqrt(sum(weights*(.-weighted.mean(., weights))^2/((n()-1)/n()*sum(weights))))))

matched_std &lt;-data.frame(t(matched_var))
matched_std$pooled &lt;- sqrt(((matched_std[,1])^2 + (matched_std[,2])^2)/2)

matched&lt;-data.frame(t(matched_means),matched_std$pooled)
matched&lt;-matched[1:33,]

colnames(matched)&lt;-c(&quot;sip_mean&quot;,&quot;oral_mean&quot;,&quot;sd&quot;)
matched$bias &lt;-(as.numeric(as.character(matched$sip_mean))-as.numeric(as.character(matched$oral_mean)))/as.numeric(as.character(matched$sd))
matched$group &lt;-rep(&quot;Matched&quot;,nrow(matched))
matched$label &lt;-rownames(matched)



#####IPTW Group
#same calcuation using the inverse probability weights
model_mat &lt;-model.matrix(~treatment +agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro+IPTW -1,oral60)

model_mat &lt;-data.frame(model_mat)
#model_mat$treatment &lt;-as.factor(model_mat$treatment)



weighted_means &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(weighted.mean(., IPTW)))

weighted_var &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(sqrt(sum(IPTW*(.-weighted.mean(., IPTW))^2/((n()-1)/n()*sum(IPTW))))))

weighted_std &lt;-data.frame(t(weighted_var))
weighted_std$pooled &lt;- sqrt(((weighted_std[,1])^2 + (weighted_std[,2])^2)/2)

weighted&lt;-data.frame(t(weighted_means),weighted_std$pooled)
weighted&lt;-weighted[1:33,]

colnames(weighted)&lt;-c(&quot;sip_mean&quot;,&quot;oral_mean&quot;,&quot;sd&quot;)
weighted$bias &lt;-(as.numeric(as.character(weighted$sip_mean))-as.numeric(as.character(weighted$oral_mean)))/as.numeric(as.character(weighted$sd))
weighted$group &lt;-rep(&quot;Logistic IPTW&quot;,nrow(weighted))
weighted$label &lt;-rownames(weighted)


#####CBPS Group
#same calculations using the covariate balance propensity score weights

model_mat &lt;-model.matrix(~treatment +agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro+cbps -1,oral60)

model_mat &lt;-data.frame(model_mat)
#model_mat$treatment &lt;-as.factor(model_mat$treatment)



cbps_means &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(weighted.mean(., cbps)))

cbps_var &lt;-model_mat %&gt;%
  group_by(treatment) %&gt;%
  summarise_all(funs(sqrt(sum(cbps*(.-weighted.mean(., cbps))^2/((n()-1)/n()*sum(cbps))))))

cbps_std &lt;-data.frame(t(cbps_var))
cbps_std$pooled &lt;- sqrt(((cbps_std[,1])^2 + (cbps_std[,2])^2)/2)

balanced&lt;-data.frame(t(cbps_means),cbps_std$pooled)
balanced&lt;-balanced[1:33,]

colnames(balanced)&lt;-c(&quot;sip_mean&quot;,&quot;oral_mean&quot;,&quot;sd&quot;)
balanced$bias &lt;-(as.numeric(as.character(balanced$sip_mean))-
                   as.numeric(as.character(balanced$oral_mean)))/as.numeric(as.character(balanced$sd))
balanced$group &lt;-rep(&quot;CBPS IPTW&quot;,nrow(balanced))
balanced$label &lt;-rownames(balanced)



#construct plot data frame from all calculations
plot_data &lt;-rbind(fullsamp,matched,weighted,balanced)
#plot_data$label &lt;-rownames(plot_data)

#change label names for presentation
plot_data$label &lt;-c(&quot;Sip&quot;,&quot;Age: &lt;55&quot;,&quot;Age: 55-64&quot;,&quot;Age: 65-74&quot;,&quot;Age: &gt;74&quot;,&quot;Race: Asian&quot;,&quot;Race: Black&quot;,&quot;Race: Hispanic&quot;, &quot;Race: Unknown&quot;,&quot;Educaton: Some College&quot;,&quot;Education: Unknown&quot;,&quot;Income: 50-99K&quot;, &quot;Income: &gt;99k&quot;, &quot;Income: Unknown&quot;,&quot;Region: East South Central&quot;,&quot;Region: Middle Atlantic&quot;, &quot;Region: Mountain&quot;,&quot;Region: New England&quot;,&quot;Region: Pacific&quot;,&quot;Region: South Atlantic&quot;,&quot;Region: Unknown&quot;,&quot;Region: West North Central&quot;,&quot;Region: West South Central&quot;,&quot;Product: Other&quot;,&quot;Product: PPO&quot;,&quot;Metastatic: Yes&quot;,&quot;ASO: Yes&quot;,&quot;Diabetes: Yes&quot;,&quot;Hypertension: Yes&quot;,&quot;CHF: Yes&quot;,&quot;Osteoporosis: Yes&quot;,&quot;Arrhythmia: Yes&quot;,&quot;Provider: Urologist&quot;)
#remove row where bias is infinite because there are no subjects in control group
&#39;%!in%&#39; &lt;- function(x,y)!(&#39;%in%&#39;(x,y))
plot_data &lt;-plot_data %&gt;%
  filter(label %!in% c(&quot;Sip&quot;,&quot;Region: Unknown&quot;,&quot;treatment&quot;))


library(ggplot2)
library(ggpubr)
library(ggsci)
#visual inspect covariate balance using ggplot
fp &lt;- ggplot(data =plot_data,aes(x=label, y=bias,color=group,shape=group)) +
  scale_shape_manual(values=c(20,18,17,15))+ 
    geom_hline(yintercept=-0.1, lty=3,size=0.7) + 
  geom_hline(yintercept=0.1,lty=3,size=0.7) + #these lines indicate the thresholds for high differences

  geom_point(size=5) + 
  geom_hline(yintercept=0, lty=2) +  # add a dotted line at x=1 after flip
  coord_flip() +  # flip coordinates (puts labels on y axis)
  xlab(&quot;Variable&quot;) + ylab(&quot;Standardized Difference&quot;) + 
  theme_minimal()+ theme(
                           axis.ticks.y=element_blank(),
                         panel.grid.minor=element_blank(),
                         legend.title=element_blank(),
                         text = element_text(size=16),
                         axis.title.x =element_text(hjust = 0.2,size=16)) #additional aesthetic options

ggpar(fp,palette=&quot;nejm&quot;)</code></pre>
<p><img src="index_files/figure-html/balance%20plot-1.png" width="768" /></p>
</div>
</div>
<div id="treatment-effect-estimation" class="section level2">
<h2>Treatment Effect Estimation</h2>
<div id="binary-outcome-visit-to-the-emergency-room-er-in-60-days" class="section level3">
<h3>Binary Outcome: Visit to the Emergency Room (ER) in 60 days</h3>
<p>The first outcome of interest is whether a patient had an emergency room (ER) visit within the first 60 days of starting their treatment. Let <span class="math inline">\(Y_{i}=1\)</span> if the <span class="math inline">\(i-th\)</span> patient had an ER visit within the first 60 days of starting their first treatment, and <span class="math inline">\(Y_{i}=0\)</span> if not. Thus, <span class="math inline">\(\pi_{i}(1)\)</span> is the probability an individual had an ER visit if they received oral therapy as first-line treatment, and <span class="math inline">\(\pi_{i}(0)\)</span> if they received the immunotherapy (sipuleucel-T). We are interested in the ratio of the odds a patient had an ER visit when treated with oral therapy to the odds a patient had an ER visit when treated with immunotherapy. We can model this odds ratio using a logistic regression model:</p>
<p><span class="math display">\[
log(\dfrac{\pi_{i}}{1-\pi_{i}}) =  \beta_{1}T_{i} 
\]</span> Where <span class="math inline">\(e^{\beta_{1}}\)</span> is the odds ratio and thus <span class="math inline">\(\pi_i\)</span> is the probability of having an ER visit for subject <span class="math inline">\(i\)</span>. This model provides the odds ratio directly from the observed data prior to our using any of the bias reduction techniques or or adjustments.</p>
<pre class="r"><code>#model the unadjusted treatment effect
mod_unad &lt;-glm(er60~treatment,data=oral60,family=binomial(link=logit))
#summarize model results
summary(mod_unad)</code></pre>
<pre><code>## 
## Call:
## glm(formula = er60 ~ treatment, family = binomial(link = logit), 
##     data = oral60)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.3020  -0.2625  -0.2625  -0.2625   2.6022  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -3.0647     0.2233 -13.728   &lt;2e-16 ***
## treatment    -0.2865     0.2506  -1.143    0.253    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 871.89  on 2833  degrees of freedom
## Residual deviance: 870.65  on 2832  degrees of freedom
## AIC: 874.65
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<pre class="r"><code>#hard to interpret results because they are still on natural log scale
#here is a quick function to exponentiate  and report estimate and confidence interval
exp_out &lt;-function(model_object){
  out&lt;-matrix(nrow=1,ncol=3)
    out[1,1] &lt;-round(exp(summary(model_object)$coefficients[2,1]),2)   
    out[1,2] &lt;-round(exp(summary(model_object)$coefficients[2,1] - 1.96*summary(model_object)$coefficients[2,2]),2)
    out[1,3] &lt;-round(exp(summary(model_object)$coefficients[2,1] + 1.96*summary(model_object)$coefficients[2,2]),2)
  colnames(out) &lt;-c(&#39;OR&#39;,&#39;Lower&#39;,&#39;Upper&#39;)
  rownames(out)&lt;-names(model_object$coefficients[2])
  print(out)
}

#now see odds ratio and confidence interval after expoentiation
exp_out(mod_unad)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.75  0.46  1.23</code></pre>
<p>After running this model, we get an estimate of 0.75 (0.46,1.23), also reported in Table 3. This odds ratio indicates that patients treated with oral therapy first line had 0.75 times the odds of an ER visit in 60 days than immunotherapy patients, before making adjustments. Next, we use the traditional covariate adjustment approach:</p>
<p><span class="math display">\[
log(\dfrac{\pi_{i}}{1-\pi_{i}}) =  \beta_{1}T_{i} +\beta_{2}X_{2i} + \beta_{3}X_{3i} + ...+ \beta_{k}X_{ki} 
\]</span> where the additional <span class="math inline">\(X\)</span>’s are the variables thought to confound assignment of treatment, such as age, race, comorbidities, and the other variables as listed previously in Table 1. The interpretation of the odds ratio <span class="math inline">\(e^{\beta_1}\)</span> changes slightly 0.80 (0.47,1.36) as we are now modeling a conditional odds ratio versus the marginal odds ratio above. This odds ratio indicates that the odds of an ER visit in 60 days for the oral therapy group are 0.8 times the odds of an ER visit for the immunotherapy group, conditional on the adjustment covariates.</p>
<pre class="r"><code>#now modeling provenge adjusting for all covariates
#not a good choice when there are many covariates
mod_adj &lt;-glm(er60~treatment+agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=oral60,family=binomial(link=logit))

exp_out(mod_adj)</code></pre>
<pre><code>##            OR Lower Upper
## treatment 0.8  0.47  1.36</code></pre>
<p>Now we compare these results to our propensity methods. We can run the marginal logistic regression model on our propensity matched dataset, obtaining an estimate of 0.91 (0.54,1.53). Notice the larger confidence interval, as the matching process reduced the sample size.</p>
<pre class="r"><code>mod_match &lt;-glm(er60~treatment,data=matched_oral,family=binomial(link=&#39;logit&#39;),weights = weights)

exp_out(mod_match)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.79  0.46  1.34</code></pre>
<pre class="r"><code>library(mgcv)
mod_prop &lt;-gam(er60~treatment+s(pr_score,k=4,m=3),data=oral60,family=binomial(link=&#39;logit&#39;))

#same output function but for GAM model objects
exp_out_gam &lt;-function(gam_model){
    out&lt;-matrix(nrow=1,ncol=3)
    out[1,1] &lt;-round(exp(gam_model$coefficients[2]),2)   
    out[1,2] &lt;-round(exp(gam_model$coefficients[2] - 1.96*sqrt(gam_model$Ve[2,2])),2)
    out[1,3] &lt;-round(exp(gam_model$coefficients[2] + 1.96*sqrt(gam_model$Ve[2,2])),2)
  colnames(out) &lt;-c(&#39;Estimate&#39;,&#39;Lower&#39;,&#39;Upper&#39;)
  rownames(out)&lt;-names(gam_model$coefficients[2])
  print(out)
}

exp_out_gam(mod_prop)</code></pre>
<pre><code>##           Estimate Lower Upper
## treatment     0.82  0.48  1.39</code></pre>
<p>Finally, we can fit the outcome model on the full dataset, now weighting each observation by the IPTW from the propensity scores estimated through logistic regression and the CBPS. Here, we use the same marginal model, using the weights for robust standard error estimation as described previously. We did so by using the R package <em>survey</em>.<span class="math inline">\(^{[56]}\)</span> The estimates from these weighted models are 0.56 (0.26,1.23) and 0.55 (0.25 1.21). None of these ORs were statistically significant, indicating that there may not be a significant difference in the odds of an ER visits between these two treatment groups. When comparing immunotherapy and chemotherapy, the weighted logistic regression and CBPS estimates are 1.51 (0.87, 2.61) and 1.85 (1.12,3.05), suggesting that chemotherapy patients may have a greater odds of an ER visit.</p>
<pre class="r"><code>library(survey)

design.ps &lt;- svydesign(ids=~1, weights=~IPTW, data=oral60)

mod_iptw&lt;-svyglm(er60~treatment,design=design.ps,family=binomial(link=&#39;logit&#39;))

exp_out(mod_iptw)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.56  0.26  1.23</code></pre>
<pre class="r"><code>design.cbps &lt;- svydesign(ids=~1, weights=~cbps, data=oral60)

mod_iptw&lt;-svyglm(er60~treatment,design=design.cbps,family=binomial(link=&#39;logit&#39;))

exp_out(mod_iptw)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.55  0.25  1.21</code></pre>
</div>
<div id="count-outcome-number-of-emergency-room-er-visits-in-180-days" class="section level3">
<h3>Count Outcome: Number of Emergency Room (ER) visits in 180 days</h3>
<p>Next, we model our count outcome, the number of ER visits, where <span class="math inline">\(Y_i\)</span> can take any positive integer values. We are interested in the difference in the expected number of ER visits between patients in the immunotherapy and oral therapy groups. We can model that difference as: <span class="math display">\[
log(\mu_{i}) = \beta _{0} + \beta_{1}T_{i} 
\]</span> where <span class="math inline">\(\mu_{i}\)</span> is the expected number of ER visits in 180 days from start of treatment. Thus, <span class="math inline">\(e^{\beta_{1}}\)</span> can tell us the factor the expected counts differ as a risk ratio. All models we fit in the binary outcome can be fit in a similar fashion to this count outcome. One key change here is the Poisson model assumes the same parameter for the expected (mean) count and the variance; we can see from Table 1 that this assumption may not hold. Thus, we accounted for this relationship by changing the dispersion parameter in our models, allowing the variance to be a factor larger than the mean. Table 3 shows the results of each method for the count outcome.</p>
<pre class="r"><code>#filter data to those with at least 180 days of enrollment
oral180&lt;-oral %&gt;%
  filter(enrolltime &gt;=180)

#use quasipoisson function to account for overdispersion
mod_unad &lt;-glm(ercount180~treatment,data=oral180,family=quasipoisson(link=&quot;log&quot;))

exp_out(mod_unad)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.92  0.56  1.52</code></pre>
<pre class="r"><code>modfullgroup2 &lt;-glm(ercount180~treatment+agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+hypertension+CHF+osteoporosis+arrythmia+uro,data=oral180,family=quasipoisson(link=&quot;log&quot;))

exp_out(modfullgroup2)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.96  0.63  1.47</code></pre>
<pre class="r"><code>matched &lt;- matchit((1-treatment)~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data =oral180, method = &quot;nearest&quot;,caliper=.2,ratio=4)

matched_sum&lt;-summary(matched)
matched_sum$nn</code></pre>
<pre><code>##           Control Treated
## All          1782     380
## Matched      1091     366
## Unmatched     691      14
## Discarded       0       0</code></pre>
<pre class="r"><code>matched_ae &lt;- match.data(matched)

matchedmodreg &lt;-glm(ercount180~treatment,data=matched_ae,family=quasipoisson(link=&quot;log&quot;),weights = weights)

exp_out(matchedmodreg)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.98  0.64  1.51</code></pre>
<pre class="r"><code>propae &lt;-glm(treatment~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=oral180,family=binomial(link=&#39;logit&#39;))

oral180$pr_score &lt;-predict(propae, type = &quot;response&quot;)

summary(oral180$pr_score)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.2323  0.7699  0.8526  0.8242  0.9242  1.0000</code></pre>
<pre class="r"><code>oral180$pr_score_trim &lt;-ifelse(oral180$pr_score&lt;.01,.01,oral180$pr_score)
oral180$pr_score_trim &lt;-ifelse(oral180$pr_score&gt;.99,.99,oral180$pr_score_trim)

oral180$IPTW &lt;-oral180$treatment/oral180$pr_score_trim + (1-oral180$treatment)/(1-oral180$pr_score_trim)


cbps &lt;-CBPS(treatment~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=oral180,standardize=FALSE,method=&quot;exact&quot;)</code></pre>
<pre><code>## [1] &quot;Finding ATT with T=1 as the treatment.  Set ATT=2 to find ATT with T=0 as the treatment&quot;</code></pre>
<pre class="r"><code>oral180$CBPS &lt;-cbps$weights

design.ps &lt;- svydesign(ids=~1, weights=~IPTW, data=oral180)

mod_iptw&lt;-svyglm(ercount180~treatment,design=design.ps,family=poisson)

exp_out(mod_iptw)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.87  0.48   1.6</code></pre>
<pre class="r"><code>design.cbps &lt;- svydesign(ids=~1, weights=~CBPS, data=oral180)

mod_iptw&lt;-svyglm(ercount180~treatment,design=design.cbps,family=poisson)

exp_out(mod_iptw)</code></pre>
<pre><code>##             OR Lower Upper
## treatment 0.88  0.41   1.9</code></pre>
<p>The models show that we can expect the same number of ER visits for patients who receive an oral therapy first-line vs. those who receive immunotherapy. For example, the matched ratio estimate is 1.00 (0.59,1.71), indicating the expected number of ER visits is the same for both treatment groups. However, we see a different pattern when comparing immunotherapy to chemotherapy, the matched ratio is 1.70 (1.00, 2.90), indicating that patients on chemotherapy have more ER visits.</p>
</div>
<div id="length-of-stay-outcomes-time-on-treatment-and-time-enrolled" class="section level3">
<h3>Length of Stay Outcomes: Time on Treatment and Time Enrolled</h3>
<p>We will now discuss the time to events outcomes previously described. For each treatment group, we are interested in the risk of stopping treatment from the all of the six focus medications, and the risk of dropping out at any given time point. These risks, or hazards, can be estimated using a proportional hazards model <span class="math display">\[
log(\dfrac{\lambda_{i}(t)}{\lambda_{0}(t)}) =  \beta_{1}T_{i} 
\]</span> where <span class="math inline">\(\lambda_{0}(t)\)</span> is the baseline hazard function for immunotherapy and <span class="math inline">\(\lambda_{i}(i)\)</span> is the hazard for treatment group <span class="math inline">\(T_{i}\)</span>. Thus, <span class="math inline">\(e^{\beta_{1}}\)</span> is a hazard ratio of the two treatment groups being compared at the same time. We used the package <em>survival</em><span class="math inline">\(^{[57]}\)</span> to fit the Cox proportional hazards models.</p>
<pre class="r"><code>library(survival)
#create a factor variable of the treatment
oral$treatment_fac&lt;-factor(oral$treatment,labels =c(&quot;Sip&quot;,&quot;AE&quot;))

mod_unad &lt;-coxph(Surv(enrolltime) ~ treatment_fac, data = oral)

out &lt;-exp(mod_unad$coefficients[1] +qnorm(c(0.5,0.025,0.975)) *(sqrt(mod_unad$var[1,1]) ))
names(out) &lt;-c(&quot;Estimate&quot;,&quot;Lower&quot;,&quot;Upper&quot;)
round(out,2)</code></pre>
<pre><code>## Estimate    Lower    Upper 
##     1.51     1.37     1.66</code></pre>
<p>Here, the matched estimate 1.15 (1.04,1.28) shows that patients who receive an oral therapy first-line were more likely to stop treatment at any given time than patients who received immunotherapy. In other words, patients who received an oral therapy first-line had a shorter total duration of time on all treatments than patients who received immunotherapy as their first-line therapy. Using the same method, patients who received chemotherapy as first-line had a hazard ratio of 1.36 (1.21,1.54) again, having a shorter duration of time on treatment than those patients who started with immunotherapy. In Table 3, we can see the estimates for the hazard ratios of ending enrollment as well, with 1.35 (1.28,1.42) comparing oral therapy to immunotherapy, and 1.31 (1.24,1.39) comparing chemotherapy to immunotherapy using the logistic IPTW method.</p>
</div>
<div id="time-varying-outcome-opioid-usage-post-treatment" class="section level3">
<h3>Time Varying Outcome: Opioid Usage Post Treatment</h3>
<p>Lastly, in those patients who had an opioid prescribed at any time, we evaluated the longitudinally varying repeated measures outcome of opioids prescribed in MME per month for patients who had baseline opioid use before starting one of the focus treatments for their prostate cancer. Each patient included in this subset had baseline opioid prescriptions (30 days prior to start of treatment) as well as 180 days of opioids prescribed after initiation of treatment. The opioid prescriptions were defined in 30-day periods. Figure 3 shows the mean of each 30-day period across the three treatment groups, with a smooth showing the overall trend.</p>
<pre class="r"><code>plot_data &lt;-firstline_opioid %&gt;%
  group_by(t,Brand) %&gt;%
  summarise(mean = mean(monthtotal), std=sqrt(var(monthtotal)), n = n(),
            median = median(monthtotal), q1=quantile(monthtotal,.25),
            q3=quantile(monthtotal,.75)) %&gt;%
  filter(t&lt;=6)

plot_data$Treatment&lt;-as.numeric(plot_data$Brand)
plot_data$Treatment&lt;-factor(plot_data$Treatment,levels=c(1,2,3),labels = c(&quot;Immunotherapy&quot;,&quot;Chemotherapy&quot;,&quot;Oral Therapy&quot;))
plot_data$provfac &lt;-factor(as.numeric(plot_data$Brand),levels=c(1,2,3),labels=c(&quot;Sip&quot;,&quot;Doc&quot;,&quot;AE&quot;))
plot_data$t &lt;- plot_data$t*30

plot_all &lt;-firstline_opioid %&gt;%
  dplyr::select(t,Brand,monthtotal) %&gt;%
  filter(t&lt;=6)

plot_all$Treatment&lt;-as.numeric(plot_all$Brand)
plot_all$Treatment&lt;-factor(plot_all$Treatment,levels=c(1,2,3),labels = c(&quot;Immunotherapy&quot;,&quot;Chemotherapy&quot;,&quot;Oral Therapy&quot;))
plot_all$provfac &lt;-factor(as.numeric(plot_all$Brand),levels=c(1,2,3),labels=c(&quot;Sip&quot;,&quot;Doc&quot;,&quot;AE&quot;))

plot_all$mean &lt;-plot_all$monthtotal

#plot_data &lt;-plot_data[plot_data$Brand!=&quot;DOC&quot;,]

p &lt;-ggplot(plot_data,aes(x=t,y=mean,group=Treatment,color=Treatment,fill=Treatment,linetype=Treatment,weight=n,shape=Treatment))   + 
geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE,size=2)+ geom_point(size=4.5) + labs(color=&#39;Treatment&#39;,x=&#39;Days Since Start of First Focus Drug&#39;,y=&#39;Mean Opioids Prescribed (MME)&#39;) + 
  scale_x_continuous(breaks = seq(0, 180, by = 30)) +theme_minimal()+ theme(#plot.title = element_text(hjust = 0.9,size=16),
                           axis.ticks.y=element_blank(),
                         panel.grid.minor=element_blank(),
                         legend.title=element_blank(),
                         text = element_text(size=16))

ggpar(p,palette=&quot;nejm&quot;)</code></pre>
<p><img src="index_files/figure-html/opioid_plot-1.png" width="768" /></p>
<p>We wish to model the trend and to test if there is any difference in mean opioid prescribing at any time point between treatment groups. We can model the quantity of opioids prescribed in MME <span class="math inline">\(Y_{ij}\)</span> at the <span class="math inline">\(j^{th}\)</span> 30 day period for each individual <span class="math inline">\(i\)</span> as:</p>
<p><span class="math display">\[
Y_{ij} = \beta_{0} + b_{0i} + \beta_{1}T_{i} + S(t_{ij}) +S(t_{ij})T_{i} +\epsilon_{ij}
\]</span></p>
<p>where <span class="math inline">\(j=1,..,n_{i}\)</span>, <span class="math inline">\(n_{i} \in \{1,2,3,4,5,6,7\}\)</span>, <span class="math inline">\(b_{0} \sim N(0,\tau^{2})\)</span> and <span class="math inline">\(\epsilon_{i} \sim MVN_{n_{i}}(0,\sigma^{2}I_{n_{i}})\)</span>. <span class="math inline">\(S(t_{ij})\)</span> is specified as a penalized regression spline with 3 degrees of freedom, allowing more flexible smooths for modeling the prescribing trend over time. We set the smooth in an interaction term to allow for different smooth trends for the immunotherapy and oral therapy treatment groups. Thus, the main parameter of interest tells us the difference in the mean opioid prescribing over time between the two groups. We can fit each of the methods in this outcome, adding covariates and smooths directly in the model, and fitting the model on a matched dataset. We use the R package <em>mgcv</em>.<span class="math inline">\(^{[58]}\)</span> Maindonald<span class="math inline">\(^{[59]}\)</span> also provides more detail on smooths when using GAM models. An important note when using IPTW and CBPS is that we are only weighting on the initial treatment, so at other time points the weights may bias the results. Also, we truncated the time to six months because many patients will only respond to or tolerate treatment for around six months before switching therapies to another focus treatment. Opiate use may parallel disease response to treatment in those who are started on opiates for their cancer. In other words, a patient’s opiate use may decrease when their cancer is improving on treatment and subsequently increase when the cancer has become resistant to treatment. Pain management beyond six months from the initial treatment is unlikely related to that treatment as many patients have changed regimens or stopped treatment altogether. Any inferences using the full time period will be heavily biased by changing therapy or require advanced methods to handle switching treatments, such as marginal structure models.60 Table 3 shows the estimated difference in mean opioid usage between groups at selected time points.</p>
<pre class="r"><code>ae&lt;-firstline_opioid[firstline_opioid$pae&lt;=1,]



ae$treatment &lt;-ae$pae
ae &lt;-ae %&gt;%
  dplyr::select(Patid,monthtotal,t,treatment,pae,agecat,racecat,educat,
              housecat,Division,
              Product,met,Aso,diabetes,
              hypertension,
              CHF,osteoporosis,arrythmia,
              uro)
ae$monthtotal &lt;-ifelse(is.na(ae$monthtotal),0,ae$monthtotal)

ae$provfac&lt;-factor(ae$pae,labels =c(&quot;Sip&quot;,&quot;AE&quot;))
ae$Patid &lt;-as.factor(ae$Patid)
ae$t &lt;-as.integer(ae$t)

ae &lt;-ae[ae$t&lt;=6,]

modfullgroup &lt;-bam(monthtotal~provfac  +s(t,by=provfac,k=3)+
                     s(Patid, bs=&quot;re&quot;,m=1),data=ae)
summary(modfullgroup)

gam.check(modfullgroup)
  p &lt;- plot_diff(modfullgroup, view=&quot;t&quot;, 
                 comp=list(provfac=c(&quot;AE&quot;, &quot;Sip&quot;)),
                 cond=list(Condition=1),
                 ylim=c(-1000,2000),
                 xlim=c(0,6),
                 main=&quot;AE-Sip&quot;,
                 col=rainbow(6)[6], 
                 rm.ranef=TRUE) #plot=FALSE
  
g&lt;-plot_smooth(modfullgroup, view = &quot;t&quot;,cond=list(provfac=c(&quot;Sip&quot;)),rm.ranef = TRUE, main=&quot;TEST&quot;,rug =FALSE)
  
  print(paste(p$est[c(1,51,99)],p$est[c(1,51,99)] - p$CI[c(1,51,99)],p$est[c(1,51,99)] + p$CI[c(1,51,99)])) 
  



modfullgroup2 &lt;-bam(monthtotal~provfac +agecat+racecat+educat+
              housecat+Division+
              Product+met+Aso+diabetes+
              hypertension+
              CHF+osteoporosis+arrythmia+
              uro  + s(t,by=provfac,k=3) +
            + s(Patid, bs=&quot;re&quot;,m=1),
            data=ae)
summary(modfullgroup2)

  
    p &lt;- plot_diff(modfullgroup2, view=&quot;t&quot;, 
                 comp=list(provfac=c(&quot;AE&quot;, &quot;Sip&quot;)),
                 cond=list(Condition=1),
                 ylim=c(-1000,2000),
                 main=&quot;AE-Sip&quot;,
                 col=rainbow(6)[6], 
                 rm.ranef=TRUE)

  print(paste(p$est[c(1,51,99)],p$est[c(1,51,99)] - p$CI[c(1,51,99)],p$est[c(1,51,99)] + p$CI[c(1,51,99)]))  
  
  ae_matching &lt;-ae %&gt;%
    group_by(Patid) %&gt;%
    filter(row_number()==1)
  
  ae_matching &lt;-data.frame(ae_matching)
  
matched &lt;- matchit(treatment~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+hypertension+CHF+osteoporosis+arrythmia+uro,data =ae_matching, method =&quot;nearest&quot;,caliper=.2,ratio=4)

matched_sum&lt;-summary(matched)
matched_sum$nn



matched_ae &lt;- match.data(matched)

matched_ids &lt;-unique(matched_ae$Patid)

m_ae &lt;- ae %&gt;%
  filter(Patid %in% matched_ids)
  
matchedmodreg &lt;-bam(monthtotal~provfac + s(t,by=provfac,k=3) +
             s(Patid, bs=&quot;re&quot;,m=1),
            data=m_ae)
summary(matchedmodreg)

    p &lt;- plot_diff(matchedmodreg, view=&quot;t&quot;, 
                 comp=list(provfac=c(&quot;AE&quot;, &quot;Sip&quot;)),
                 cond=list(Condition=1),
                 ylim=c(-1000,2000),
                 main=&quot;AE-Sip&quot;,
                 col=rainbow(6)[6], 
                 rm.ranef=TRUE)

        print(paste(p$est[c(1,51,99)],p$est[c(1,51,99)] - p$CI[c(1,51,99)],p$est[c(1,51,99)] + p$CI[c(1,51,99)])) 


propae &lt;-glm(provfac~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=ae_matching,family=binomial(link=&#39;logit&#39;))

ae_matching$pr_score &lt;-predict(propae, type = &quot;response&quot;)

summary(ae_matching$pr_score)

ae_matching$pr_score_trim &lt;-ifelse(ae_matching$pr_score&lt;.01,.01,ae_matching$pr_score)
ae_matching$pr_score_trim &lt;-ifelse(ae_matching$pr_score&gt;.99,.99,ae_matching$pr_score_trim)

ae_matching$IPTW &lt;-ae_matching$treatment/ae_matching$pr_score_trim + (1-ae_matching$treatment)/(1-ae_matching$pr_score_trim)

cbps &lt;-CBPS(treatment~agecat+racecat+educat+housecat+Division+Product+met+Aso+diabetes+
  hypertension+CHF+osteoporosis+arrythmia+uro,data=ae_matching,standardize=TRUE,method=&quot;exact&quot;)
ae_matching$CBPS &lt;-cbps$weights

#normalize weights for bam
ae_matching$st_weight &lt;-ae_matching$IPTW / mean(ae_matching$IPTW)

ae_matching&lt;-data.frame(ae_matching)

ae_matching &lt;- ae_matching %&gt;%
            dplyr::select(Patid,pr_score,pr_score_trim,IPTW,CBPS,st_weight)

ae &lt;-left_join(ae,ae_matching,by=&quot;Patid&quot;)

prep &lt;-bam(monthtotal~provfac + s(t,by=provfac,k=3) + s(pr_score,k=4) +
            s(Patid, bs=&quot;re&quot;,m=1),
            data=ae)
summary(prep)

p &lt;- plot_diff(prep, view=&quot;t&quot;, 
                 comp=list(provfac=c(&quot;AE&quot;, &quot;Sip&quot;)),
                 cond=list(Condition=1),
                 ylim=c(-1000,2000),
                 main=&quot;AE-Sip&quot;,
                 col=rainbow(6)[6], 
                 rm.ranef=TRUE)

   print(paste(p$est[c(1,51,99)],p$est[c(1,51,99)] - p$CI[c(1,51,99)],p$est[c(1,51,99)] + p$CI[c(1,51,99)])) 

aeiptw &lt;-bam(monthtotal~provfac + s(t,by=provfac,k=3) +  
             s(Patid, bs=&quot;re&quot;,m=1),
            data=ae, weights = st_weight)

summary(aeiptw)


p &lt;- plot_diff(aeiptw, view=&quot;t&quot;, 
                 comp=list(provfac=c(&quot;AE&quot;, &quot;Sip&quot;)),
                 cond=list(Condition=1),
                 ylim=c(-1000,2000),
                 main=&quot;AE-Sip&quot;,
                 col=rainbow(6)[6], 
                 rm.ranef=TRUE)

        print(paste(p$est[c(1,51,99)],p$est[c(1,51,99)] - p$CI[c(1,51,99)],p$est[c(1,51,99)] + p$CI[c(1,51,99)])) 
   
   
 aecbps &lt;-bam(monthtotal~provfac + s(t,by=provfac,k=3) +  
             s(Patid, bs=&quot;re&quot;,m=1),
            data=ae, weights = CBPS)

summary(aecbps)


p &lt;- plot_diff(aecbps, view=&quot;t&quot;, 
                 comp=list(provfac=c(&quot;AE&quot;, &quot;Sip&quot;)),
                 cond=list(Condition=1),
                 ylim=c(-1000,2000),
                 main=&quot;AE-Sip&quot;,
                 col=rainbow(6)[6], 
                 rm.ranef=TRUE)

        print(paste(p$est[c(1,51,99)],p$est[c(1,51,99)] - p$CI[c(1,51,99)],p$est[c(1,51,99)] + p$CI[c(1,51,99)])) </code></pre>
<p>For example, the difference in MME prescribed to an average individual in the immunotherapy group vs. the oral therapy group at treatment start is -83 MME (CI -391, 224) in the unadjusted model. In other words, among patients prescribed opioids, the average individual in the immunotherapy group treatment is predicted to have 83 more MME’s of prescribed opioids than the average individual in the oral therapy group at treatment start; however, this difference is not significantly significant. This estimate changes 90 days post treatment start to -130 MME (CI -380, 121) demonstrating how the estimate varies across time. We did not detect any significant differences in opioid usage at any time point, for both the oral and immunotherapy comparison and the chemotherapy and immunotherapy comparison.</p>
</div>
</div>
<div id="discussion" class="section level2">
<h2>Discussion</h2>
<p>We have presented a very simple and standard use of propensity methods for estimating the causal effects of a treatment on the outcomes of interest that are routinely used. We showed methods that can make the comparison groups more balanced on a large number of characteristics, and thus provide more accurate estimates of possible causal relationships. To illustrate these methods, we analyzed treatment outcomes for different therapies used to treat patients with advanced prostate cancer. The results above showed that patients who received chemotherapy (docetaxel) first-line may have more frequent trips to the emergency room in the first six months compared to patients who receive immunotherapy (sipuleucel-T) as first-line therapy. The results also demonstrated that patients who received immunotherapy first-line may have longer total time on all treatments (first-line and subsequent treatments) than patients whose first-line therapy is an oral therapy or chemotherapy. Finally, among patients who already have a baseline opioid requirement for pain control when they initiated treatment for advanced prostate cancer, we saw higher average baseline requirements among those patients who were started on chemotherapy than those patients who were started on immunotherapy. However, patients in the chemotherapy group appeared to have better pain control after starting treatment than those patients started on immunotherapy.<br />
There are inherent limitations to the data, as the Clinformatics TM Data Mart Database is designed for billing purposes and not for research. Thus, the data is subject to misclassification of diagnosis codes and is missing socioeconomic values for many individuals. Although we could not identify if an individual was correctly classified as having prostate cancer, we only included those that also had a pharmacy claim of one of the six focus medications which are primarily used for advanced prostate cancer. Those individuals with missing sociodemographic information were still included in the analysis and treated as a separate category.</p>
<p>A significant limitation to making any clinical conclusions about prostate cancer outcomes with the findings in this paper is that prostate cancer is a heterogeneous cancer, with a wide variation in prognosis and expected responses to therapy, even in the metastatic setting. Thus, a major unmeasured confounder when studying prostate cancer in claims data is the extent of disease at initiation of treatment. This unmeasured confounder may explain some of the observed effects on our outcomes. Claims can identify if a patient is metastatic but cannot identify the extent of their metastases. This limitation has significant implications if one were to clinically interpret the data. For example, when comparing opioid requirements and differences of opioid use among treatment groups, we cannot ascertain whether a patient is using opioids for their cancer or for another reason. It’s possible that patients in the immunotherapy group who have a baseline opioid requirement may use opioids for a condition unrelated to their advanced prostate cancer, as opposed to patients in the chemotherapy or oral therapy group. In addition, while we could identify when a patient visited the ER, we did not have the reason a patient visited the ER available. Patients may be presenting to the ER due to their disease, toxicities of the treatment, or another reason unrelated to their disease or treatment. These other un-related factors may be driving the large odds ratios observed between chemotherapy and immunotherapy patients. Identifying the fact that patients treated with chemotherapy first-line visit the ER more frequently may be signaling the fact that patients treated with chemotherapy first-line have more severe prostate cancer with more associated problems that require ER evaluation.</p>
<p>Some of these limitations are inherent to analyzing claims data. If we were able to control for disease severity at initiation of treatment, than an increased odds of visiting the ER would more reliably indicate a higher toxicity of therapy, or less control of disease from the treatment. Furthermore, since we cannot control for disease severity, we are not able to confidently say that patients who received immunotherapy are on treatment longer because of immunotherapy – we are only able to conclude that they remain on treatment longer. It’s possible that patients started on immunotherapy have less aggressive disease at the start of therapy. However, interestingly, we did find that the increased time that patients in the immunotherapy group remained enrolled (potential surrogate for survival) compared to patients in the other two groups was longer than the differences we saw when comparing the amount of time on treatment. While impossible to conclude from these data, these data do suggest it’s possible that patients who receive immunotherapy first-line may derive a longer-term benefit that is demonstrated even after all treatment is discontinued. For this comparison we used the dates from the last claim per individual as a censored time endpoint, as death records were unavailable. While the true death date is ideal, this endpoint is an underestimate for all prostate cancer patients and is a right censored measure of survival. These limitations are important for researchers to recognize, as the methods do provide conclusive interpretations when all confounders are controlled, however they do not overcome fundamental limitations of the data. Thus, researchers must be very cognizant of what variables are available, are used, and if they are adequate for causal interpretation.</p>
<p>There are also challenges and drawbacks to the methods used here. Propensity methods rely on correct specification of the propensity model. Here, we used a theoretical framework, pre-emptively specifying which variables are most associated with assignment of treatment, such as age, economic status, and pre-existing comorbid conditions. These variables were considered as potential confounders to both treatment and outcome assessment. We were unable to account for all known confounders, and thus the propensity model may not have addressed all imbalance between groups. Another potential limitation to this method is that we used a logistic regression model to calculate the propensity scores. While this model allows for natural interpretation of the variables included (which may still be of interest), it may be poor at predicting propensity in comparison to machine learning models.<span class="math inline">\(^{[22]}\)</span> Furthermore, the uncertainty around the propensity estimates is not accounted for in the outcome models, and thus lead to incorrect inference and confidence with the estimates.<span class="math inline">\(^{[15]}\)</span> Additionally, we effectively have three treatments of interest, yet we stratified the data to have two separate, independent analyses, of two treatment groups. This provided easier calculation and matching from propensity; however, segmenting may mis-specify the treatment allocation mechanisms, as in practice all options are available. Generalized propensity scores can be calculated for multiple categories, with the cost of considerably greater complexity.<span class="math inline">\(^{[61,62]}\)</span> Nonetheless, the methods are very useful for two clear treatment groups to be compared, and when there are many confounding variables. Finally, significant findings found using propensity methods may be still be sensitive to a confounder that was not included in the analysis. Sensitivity analysis can test how much the estimate may change due to an unobserved variable.<span class="math inline">\(^{[50]}\)</span></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>In summary, the methods shown are very standard and routinely used tools for estimating causal effects from observed data in claims databases. It is important to note that these tools cannot perfectly answer causal questions, even with the most extensive data. There are assumptions that need to be met for causal interpretation of these estimates and they are often not verifiable from observed data. Thus, careful consideration is required by the researchers as to what variables are confounding treatment and outcome, and what method and assumptions best fit the study.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ol style="list-style-type: decimal">
<li><p>Tyree, P. T., Lind, B. K., &amp; Lafferty, W. E. (2006). Challenges of using medical insurance claims data for utilization analysis. American Journal of Medical Quality : The Official Journal of the American College of Medical Quality, 21(4), 269–275. <a href="https://doi.org/10.1177/1062860606288774" class="uri">https://doi.org/10.1177/1062860606288774</a></p></li>
<li><p>Motheral, B., Brooks, J., Clark, M. A., Crown, W. H., Davey, P., Hutchins, D., … Stang, P. (2003). A Checklist for Retrospective Database Studies—Report of the ISPOR Task Force on Retrospective Databases. Value in Health, 6(2), 90–97. <a href="https://doi.org/10.1046/J.1524-4733.2003.00242.X" class="uri">https://doi.org/10.1046/J.1524-4733.2003.00242.X</a></p></li>
<li><p>Sherman, R. E., Anderson, S. A., Dal Pan, G. J., Gray, G. W., Gross, T., Hunter, N. L., … Califf, R. M. (2016). Real-World Evidence — What Is It and What Can It Tell Us? New England Journal of Medicine, 375(23), 2293–2297. <a href="https://doi.org/10.1056/NEJMsb1609216" class="uri">https://doi.org/10.1056/NEJMsb1609216</a></p></li>
<li><p>Birnbaum, H. G., Cremieux, P. Y., Greenberg, P. E., LeLorier, J., Ostrander, J., &amp; Venditti, L. (1999). Using Healthcare Claims Data for Outcomes Research and Pharmacoeconomic Analyses. PharmacoEconomics, 16(1), 1–8. <a href="https://doi.org/10.2165/00019053-199916010-00001" class="uri">https://doi.org/10.2165/00019053-199916010-00001</a></p></li>
<li><p>Johnson, M. L., Crown, W., Martin, B. C., Dormuth, C. R., &amp; Siebert, U. (2009). Good Research Practices for Comparative Effectiveness Research: Analytic Methods to Improve Causal Inference from Nonrandomized Studies of Treatment Effects Using Secondary Data Sources: The ISPOR Good Research Practices for Retrospective Database Analysis Task Force Report—Part III. Value in Health, 12(8), 1062–1073. <a href="https://doi.org/10.1111/J.1524-4733.2009.00602.X" class="uri">https://doi.org/10.1111/J.1524-4733.2009.00602.X</a></p></li>
<li><p>Berger, M. L., Sox, H., Willke, R. J., Brixner, D. L., Eichler, H.-G., Goettsch, W., … Daniel Mullins, C. (2017). Good practices for real-world data studies of treatment and/or comparative effectiveness: Recommendations from the joint ISPOR-ISPE Special Task Force on real-world evidence in health care decision making. Pharmacoepidemiology and Drug Safety, 26(9), 1033–1039. <a href="https://doi.org/10.1002/pds.4297" class="uri">https://doi.org/10.1002/pds.4297</a></p></li>
<li><p>Ali, M. S., Groenwold, R. H. H., Belitser, S. V., Pestman, W. R., Hoes, A. W., Roes, K. C. B., … Klungel, O. H. (2015). Reporting of covariate selection and balance assessment in propensity score analysis is suboptimal: a systematic review. Journal of Clinical Epidemiology, 68(2), 122–131. <a href="https://doi.org/10.1016/J.JCLINEPI.2014.08.011" class="uri">https://doi.org/10.1016/J.JCLINEPI.2014.08.011</a></p></li>
<li><p>Weitzen, S., Lapane, K. L., Toledano, A. Y., Hume, A. L., &amp; Mor, V. (2004). Principles for modeling propensity scores in medical research: a systematic literature review. Pharmacoepidemiology and Drug Safety, 13(12), 841–853. <a href="https://doi.org/10.1002/pds.969" class="uri">https://doi.org/10.1002/pds.969</a></p></li>
<li><p>Austin, P. C. (2008). A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003. Statistics in Medicine, 27(12), 2037–2049. <a href="https://doi.org/10.1002/sim.3150" class="uri">https://doi.org/10.1002/sim.3150</a></p></li>
<li><p>D’ASCENZO, F., CAVALLERO, E., BIONDI-ZOCCAI, G., MORETTI, C., OMEDÈ, P., BOLLATI, M., … SHEIBAN, I. (2012). Use and Misuse of Multivariable Approaches in Interventional Cardiology Studies on Drug-Eluting Stents: A Systematic Review. Journal of Interventional Cardiology, 25(6), 611–621. <a href="https://doi.org/10.1111/j.1540-8183.2012.00753.x" class="uri">https://doi.org/10.1111/j.1540-8183.2012.00753.x</a></p></li>
<li><p>Deb, S., Austin, P. C., Tu, J. V., Ko, D. T., Mazer, C. D., Kiss, A., &amp; Fremes, S. E. (2016). A Review of Propensity-Score Methods and Their Use in Cardiovascular Research. Canadian Journal of Cardiology, 32(2), 259–265. <a href="https://doi.org/10.1016/J.CJCA.2015.05.015" class="uri">https://doi.org/10.1016/J.CJCA.2015.05.015</a></p></li>
<li><p>Yao, X. I., Wang, X., Speicher, P. J., Hwang, E. S., Cheng, P., Harpole, D. H., … Pang, H. H. (2017). Reporting and Guidelines in Propensity Score Analysis: A Systematic Review of Cancer and Cancer Surgical Studies. JNCI: Journal of the National</p></li>
<li><p>Singh, J. A., &amp; Cleveland, J. D. (2019). Comparative effectiveness of allopurinol and febuxostat for the risk of atrial fibrillation in the elderly: a propensity-matched analysis of Medicare claims data. European Heart Journal. <a href="https://doi.org/10.1093/eurheartj/ehz154" class="uri">https://doi.org/10.1093/eurheartj/ehz154</a></p></li>
<li><p>Austin, P. C. (2011). An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies. Multivariate Behavioral Research, 46(3), 399–424. <a href="https://doi.org/10.1080/00273171.2011.568786" class="uri">https://doi.org/10.1080/00273171.2011.568786</a></p></li>
<li><p>Stuart, E. A., DuGoff, E., Abrams, M., Salkever, D., &amp; Steinwachs, D. (2013). Estimating causal effects in observational studies using Electronic Health Data: Challenges and (some) solutions. EGEMS (Washington, DC), 1(3), 1038. <a href="https://doi.org/10.13063/2327-9214.1038" class="uri">https://doi.org/10.13063/2327-9214.1038</a></p></li>
<li><p>Brookhart, M. A., Wyss, R., Layton, J. B., &amp; Stürmer, T. (2013). Propensity score methods for confounding control in nonexperimental research. Circulation. Cardiovascular Quality and Outcomes, 6(5), 604–611. <a href="https://doi.org/10.1161/CIRCOUTCOMES.113.000359" class="uri">https://doi.org/10.1161/CIRCOUTCOMES.113.000359</a></p></li>
<li><p>Rubin, D. B. (1974). ESTIMATING CAUSAL EFFECTS OF TREATMENTS IN RANDOMIZED AND NONRANDOMIZED STUDIES 1. Journal of Educational Psychology (Vol. 66). Retrieved from <a href="http://www.fsb.muohio.edu/lij14/420_paper_Rubin74.pdf" class="uri">http://www.fsb.muohio.edu/lij14/420_paper_Rubin74.pdf</a></p></li>
<li><p>Rubin, D. B. (2005). Causal Inference Using Potential Outcomes: Design, Modeling, Decisions. <a href="https://doi.org/10.1198/016214504000001880" class="uri">https://doi.org/10.1198/016214504000001880</a></p></li>
<li><p>Imbens, G. W. (2004). Nonparametric Estimation of Average Treatment Effects under Exogeneity: A Review Author(s): Guido W. Imbens Source: The Review of Economics and Statistics NONPARAMETRIC ESTIMATION OF AVERAGE TREATMENT EFFECTS UNDER EXOGENEITY: A REVIEW* (Vol. 86). Retrieved from <a href="https://faculty.smu.edu/millimet/classes/eco7377/papers/imbens" class="uri">https://faculty.smu.edu/millimet/classes/eco7377/papers/imbens</a> 04.pdf</p></li>
<li><p>Lunceford, J. K., &amp; Davidian, M. (n.d.). Stratification and Weighting Via the Propensity Score in Estimation of Causal Treatment Effects: A Comparative Study. Retrieved from <a href="https://www4.stat.ncsu.edu/~davidian/statinmed.pdf" class="uri">https://www4.stat.ncsu.edu/~davidian/statinmed.pdf</a></p></li>
<li><p>Rosenbaum, P. R., &amp; Rubin, D. B. (1983). The Central Role of the Propensity Score in Observational Studies for Causal Effects. Biometrika (Vol. 70). Retrieved from <a href="http://www.stat.cmu.edu/~ryantibs/journalclub/rosenbaum_1983.pdf" class="uri">http://www.stat.cmu.edu/~ryantibs/journalclub/rosenbaum_1983.pdf</a></p></li>
<li><p>Lee, B. K., Lessler, J., &amp; Stuart, E. A. (2010). Improving propensity score weighting using machine learning. Statistics in Medicine, 29(3), 337–346. <a href="https://doi.org/10.1002/sim.3782" class="uri">https://doi.org/10.1002/sim.3782</a></p></li>
<li><p>Setoguchi, S., Schneeweiss, S., Brookhart, M. A., Glynn, R. J., &amp; Cook, E. F. (2008). Evaluating uses of data mining techniques in propensity score estimation: a simulation study. Pharmacoepidemiology and Drug Safety, 17(6), 546–555. <a href="https://doi.org/10.1002/pds.1555" class="uri">https://doi.org/10.1002/pds.1555</a></p></li>
<li><p>Westreich, D., Lessler, J., &amp; Funk, M. J. (2010). Propensity score estimation: neural networks, support vector machines, decision trees (CART), and meta-classifiers as alternatives to logistic regression. Journal of Clinical Epidemiology, 63(8), 826–833. <a href="https://doi.org/10.1016/J.JCLINEPI.2009.11.020" class="uri">https://doi.org/10.1016/J.JCLINEPI.2009.11.020</a></p></li>
<li><p>Imai, K., &amp; Ratkovic, M. (2013). Covariate balancing propensity score. J. R. Statist. Soc. B (Vol. 76). <a href="https://doi.org/10.1111/rssb.12027" class="uri">https://doi.org/10.1111/rssb.12027</a></p></li>
<li><p>Wyss, R., Ellis, A. R., Brookhart, M. A., Girman, C. J., Jonsson Funk, M., LoCasale, R., &amp; Stürmer, T. (2014). The Role of Prediction Modeling in Propensity Score Estimation: An Evaluation of Logistic Regression, bCART, and the Covariate-Balancing Propensity Score. American Journal of Epidemiology, 180(6), 645–655. <a href="https://doi.org/10.1093/aje/kwu181" class="uri">https://doi.org/10.1093/aje/kwu181</a></p></li>
<li><p>Rubin, D. B., &amp; Thomas, N. (1996). Matching Using Estimated Propensity Scores: Relating Theory to Practice. Biometrics, 52(1), 249. <a href="https://doi.org/10.2307/2533160" class="uri">https://doi.org/10.2307/2533160</a></p></li>
<li><p>Rubin, D. B. (1997). Estimating Causal Effects from Large Data Sets Using Propensity Scores. Annals of Internal Medicine, 127(8_Part_2), 757. <a href="https://doi.org/10.7326/0003-4819-127-8_Part_2-199710151-00064" class="uri">https://doi.org/10.7326/0003-4819-127-8_Part_2-199710151-00064</a></p></li>
<li><p>Perkins, S. M., Tu, W., Underhill, M. G., Zhou, X.-H., &amp; Murray, M. D. (2000). The use of propensity scores in pharmacoepidemiologic research. Pharmacoepidemiology and Drug Safety, 9(2), 93–101. <a href="https://doi.org/10.1002/(SICI)1099-1557(200003/04)9:2" class="uri">https://doi.org/10.1002/(SICI)1099-1557(200003/04)9:2</a>&lt;93::AID-PDS474&gt;3.0.CO;2-I</p></li>
<li><p>Brookhart, M. A., Schneeweiss, S., Rothman, K. J., Glynn, R. J., Avorn, J., &amp; Stürmer, T. (2006). Variable Selection for Propensity Score Models. American Journal of Epidemiology, 163(12), 1149–1156. <a href="https://doi.org/10.1093/aje/kwj149" class="uri">https://doi.org/10.1093/aje/kwj149</a></p></li>
<li><p>VanderWeele, T. J. (2019). Principles of confounder selection. European Journal of Epidemiology, 34(3). <a href="https://doi.org/10.1007/s10654-019-00494-6" class="uri">https://doi.org/10.1007/s10654-019-00494-6</a></p></li>
<li><p>Schneeweiss, S., Rassen, J. A., Glynn, R. J., Avorn, J., Mogun, H., &amp; Brookhart, M. A. (2009). High-dimensional propensity score adjustment in studies of treatment effects using health care claims data. Epidemiology (Cambridge, Mass.), 20(4), 512–522. <a href="https://doi.org/10.1097/EDE.0b013e3181a663cc" class="uri">https://doi.org/10.1097/EDE.0b013e3181a663cc</a></p></li>
<li><p>Schneeweiss, S., Eddings, W., Glynn, R. J., Patorno, E., Rassen, J., &amp; Franklin, J. M. (2017). Variable Selection for Confounding Adjustment in High-dimensional Covariate Spaces When Analyzing Healthcare Databases. Epidemiology, 28(2), 237–248. <a href="https://doi.org/10.1097/EDE.0000000000000581" class="uri">https://doi.org/10.1097/EDE.0000000000000581</a></p></li>
<li><p>Rosenbaum, P. R., &amp; Rubin, D. B. (1984). Reducing Bias in Observational Studies Using Subclassification on the Propensity Score. Journal of the American Statistical Association, 79(387), 516. <a href="https://doi.org/10.2307/2288398" class="uri">https://doi.org/10.2307/2288398</a></p></li>
<li><p>Austin, P. C., Grootendorst, P., &amp; Anderson, G. M. (2007). A comparison of the ability of different propensity score models to balance measured variables between treated and untreated subjects: a Monte Carlo study. Statistics in Medicine, 26(4), 734–753. <a href="https://doi.org/10.1002/sim.2580" class="uri">https://doi.org/10.1002/sim.2580</a></p></li>
<li><p>Austin, P. C. (2009). The Relative Ability of Different Propensity Score Methods to Balance Measured Covariates Between Treated and Untreated Subjects in Observational Studies. Medical Decision Making, 29(6), 661–677. <a href="https://doi.org/10.1177/0272989X09341755" class="uri">https://doi.org/10.1177/0272989X09341755</a></p></li>
<li><p>Rosenbaum, P. R., &amp; Rubin, D. B. (1985). The bias due to incomplete matching. Biometrics, 41(1), 103–116. <a href="https://doi.org/10.2307/2530647" class="uri">https://doi.org/10.2307/2530647</a></p></li>
<li><p>Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical Science : A Review Journal of the Institute of Mathematical Statistics, 25(1), 1–21. <a href="https://doi.org/10.1214/09-STS313" class="uri">https://doi.org/10.1214/09-STS313</a></p></li>
<li><p>Austin, P. C. (2011). Optimal caliper widths for propensity‐score matching when estimating differences in means and differences in proportions in observational studies. Pharmaceutical Statistics, 10(2), 150–161. <a href="https://doi.org/10.1002/PST.433" class="uri">https://doi.org/10.1002/PST.433</a></p></li>
<li><p>Rosenbaum, P. R. (1987a). Model-Based Direct Adjustment. Journal of the American Statistical Association, 82(398), 387–394. <a href="https://doi.org/10.1080/01621459.1987.10478441" class="uri">https://doi.org/10.1080/01621459.1987.10478441</a></p></li>
<li><p>Joffe, M. M., Ten Have, T. R., Feldman, H. I., &amp; Kimmel, S. E. (2004). Model Selection, Confounder Control, and Marginal Structural Models. The American Statistician, 58(4), 272–279. <a href="https://doi.org/10.1198/000313004X5824" class="uri">https://doi.org/10.1198/000313004X5824</a></p></li>
<li><p>Morgan, S. L., &amp; Todd, J. J. (2008). 6. A Diagnostic Routine for the Detection of Consequential Heterogeneity of Causal Effects. Sociological Methodology, 38(1), 231–282. <a href="https://doi.org/10.1111/j.1467-9531.2008.00204.x" class="uri">https://doi.org/10.1111/j.1467-9531.2008.00204.x</a></p></li>
<li><p>Scharfstein, D. O., Rotnitzky, A., &amp; Robins, J. M. (1999). Adjusting for Nonignorable Drop-Out Using Semiparametric Nonresponse Models. Retrieved from <a href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/343/2013/03/3R13de29.pdf" class="uri">https://cdn1.sph.harvard.edu/wp-content/uploads/sites/343/2013/03/3R13de29.pdf</a></p></li>
<li><p>Lee, B. K., Lessler, J., &amp; Stuart, E. A. (2011). Weight Trimming and Propensity Score Weighting. PLoS ONE, 6(3), e18174. <a href="https://doi.org/10.1371/journal.pone.0018174" class="uri">https://doi.org/10.1371/journal.pone.0018174</a></p></li>
<li><p>Li, F., Morgan, K. L., &amp; Zaslavsky, A. M. (2018). Balancing Covariates via Propensity Score Weighting. Journal of the American Statistical Association, 113(521), 390–400. <a href="https://doi.org/10.1080/01621459.2016.1260466" class="uri">https://doi.org/10.1080/01621459.2016.1260466</a></p></li>
<li><p>Rosenbaum, P. R., &amp; Rubin, D. B. (1985). Constructing a Control Group Using Multivariate Matched Sampling Methods That Incorporate the Propensity Score. The American Statistician, 39(1), 33. <a href="https://doi.org/10.2307/2683903" class="uri">https://doi.org/10.2307/2683903</a></p></li>
<li><p>Rosenbaum, P. R., &amp; Rubin, D. B. (1985). Constructing a Control Group Using Multivariate Matched Sampling Methods That Incorporate the Propensity Score. The American Statistician, 39(1), 33. <a href="https://doi.org/10.2307/2683903" class="uri">https://doi.org/10.2307/2683903</a></p></li>
<li><p>Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity-score matched samples. Statistics in Medicine, 28(25), 3083–3107. <a href="https://doi.org/10.1002/sim.3697" class="uri">https://doi.org/10.1002/sim.3697</a></p></li>
<li><p>Austin, P. C. (2008). Assessing balance in measured baseline covariates when using many-to-one matching on the propensity-score. <a href="https://doi.org/10.1002/pds.1674" class="uri">https://doi.org/10.1002/pds.1674</a></p></li>
<li><p>Liu, W., Kuramoto, S. J., &amp; Stuart, E. A. (2013). An introduction to sensitivity analysis for unobserved confounding in nonexperimental prevention research. Prevention Science : The Official Journal of the Society for Prevention Research, 14(6), 570–580. <a href="https://doi.org/10.1007/s11121-012-0339-5" class="uri">https://doi.org/10.1007/s11121-012-0339-5</a></p></li>
<li><p>Elixhauser A,, C. S. D. R. H. R. M. C. (1998). Comorbidity Measures for Use with Administrative Data. Medical Care, 36(1), 8–27</p></li>
<li><p>Elixhauser A.. (2014) Clinical Classifications Software (CCS) U.S. Agency for Healthcare Research and Quality</p></li>
<li><p>National Center for Injury Prevention and Control. CDC compilation of benzodiazepines, muscle relaxants, stimulants, zolpidem, and opioid analgesics with oral morphine milligram equivalent conversion factors, 2018 version. Atlanta, GA: Centers for Disease Control and Prevention; 2018. Available at <a href="https://www.cdc.gov/drugoverdose/resources/data.html" class="uri">https://www.cdc.gov/drugoverdose/resources/data.html</a></p></li>
<li><p>Heinze, G., Ploner, M., Dunkler, D., Southworth, H., &amp; Maintainer, ]. (2018). Package “logistf” Title Firth’s Bias-Reduced Logistic Regression. Retrieved from <a href="https://cran.r-project.org/web/packages/logistf/logistf.pdf" class="uri">https://cran.r-project.org/web/packages/logistf/logistf.pdf</a></p></li>
<li><p>Ho, D. E., Imai, K., King, G., &amp; Stuart, E. A. (2007). Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference. Political Analysis, 15(03), 199–236. <a href="https://doi.org/10.1093/pan/mpl013" class="uri">https://doi.org/10.1093/pan/mpl013</a></p></li>
<li><p>Lumley, T., Maintainer``, M., &amp; Lumley’’, T. (2019). Package “survey” Title Analysis of Complex Survey Samples. Retrieved from <a href="http://r-survey.r-forge.r-project.org/survey/" class="uri">http://r-survey.r-forge.r-project.org/survey/</a></p></li>
<li><p>Therneau, T. M., &amp; Grambsch, P. M. (2000). Modeling survival data : extending the Cox model. Springer. Retrieved from <a href="https://cran.r-project.org/web/packages/survival/citation.html" class="uri">https://cran.r-project.org/web/packages/survival/citation.html</a></p></li>
<li><p>Wood, S.N. (2017) Generalized Additive Models: An Introduction with R (2nd edition). Chapman and Hall/CRC</p></li>
<li><p>Maindonald, J. (2010). Smoothing Terms in GAM Models. Retrieved from <a href="http://wwwmaths.anu.edu.au/~johnm/r-book/xtras/lm-compute.pdf" class="uri">http://wwwmaths.anu.edu.au/~johnm/r-book/xtras/lm-compute.pdf</a>.</p></li>
<li><p>Cole, S. R., &amp; Hernán, M. A. (2008). Constructing Inverse Probability Weights for Marginal Structural Models. American Journal of Epidemiology, 168(6), 656–664. <a href="https://doi.org/10.1093/aje/kwn164" class="uri">https://doi.org/10.1093/aje/kwn164</a></p></li>
<li><p>Hirano, K., &amp; Imbens, G. W. (n.d.). The propensity score with continuous treatments. Retrieved from <a href="http://www.math.mcgill.ca/dstephens/SISCR2017/Articles/HIrano-Imbens-2004.pdf" class="uri">http://www.math.mcgill.ca/dstephens/SISCR2017/Articles/HIrano-Imbens-2004.pdf</a></p></li>
<li><p>Austin, P. C. (2018). Assessing the performance of the generalized propensity score for estimating the effect of quantitative or continuous exposures on binary outcomes. Statistics in Medicine, 37(11), 1874–1894. <a href="https://doi.org/10.1002/sim.7615" class="uri">https://doi.org/10.1002/sim.7615</a></p></li>
</ol>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
